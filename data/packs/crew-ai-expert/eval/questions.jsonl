{"id": "ca_001", "domain": "crew_ai_expert", "difficulty": "easy", "question": "What is CrewAI and what problem does it solve?", "ground_truth": "CrewAI is the leading open-source multi-agent orchestration framework that enables developers to build, deploy, and manage teams of AI agents working together to solve complex tasks through coordinated collaboration.", "source": "introduction"}
{"id": "ca_002", "domain": "crew_ai_expert", "difficulty": "easy", "question": "Name the three primary agent roles in CrewAI's role-based design pattern.", "ground_truth": "The three primary agent roles are Manager (orchestrates and delegates work), Worker (executes specific tasks), and Researcher (gathers and analyzes information).", "source": "agents"}
{"id": "ca_003", "domain": "crew_ai_expert", "difficulty": "easy", "question": "What is the purpose of task descriptions in CrewAI?", "ground_truth": "Task descriptions define what needs to be accomplished, providing clear instructions and context that guide agents on how to execute the task and what outcomes are expected.", "source": "tasks"}
{"id": "ca_004", "domain": "crew_ai_expert", "difficulty": "easy", "question": "What are guardrails in CrewAI tasks?", "ground_truth": "Guardrails are constraints and rules applied to tasks that ensure agents operate within defined boundaries, preventing unwanted behaviors and maintaining quality standards in task execution.", "source": "tasks"}
{"id": "ca_005", "domain": "crew_ai_expert", "difficulty": "easy", "question": "What is the difference between sequential and hierarchical processes in CrewAI crews?", "ground_truth": "Sequential processes execute tasks one after another in a defined order, while hierarchical processes involve a manager agent that orchestrates and delegates tasks to worker agents based on dependencies and priorities.", "source": "crews"}
{"id": "ca_006", "domain": "crew_ai_expert", "difficulty": "easy", "question": "How do you start a crew execution in CrewAI?", "ground_truth": "A crew execution is started using the kickoff method, which initiates the crew's process and begins execution of its tasks according to the defined process type.", "source": "crews"}
{"id": "ca_007", "domain": "crew_ai_expert", "difficulty": "easy", "question": "What are flows in CrewAI?", "ground_truth": "Flows are event-driven workflows in CrewAI that enable dynamic task orchestration with state management, allowing for complex conditional logic and branching execution paths.", "source": "flows"}
{"id": "ca_008", "domain": "crew_ai_expert", "difficulty": "easy", "question": "How many built-in tools does CrewAI provide?", "ground_truth": "CrewAI provides over 100 built-in tools that agents can use out-of-the-box for common operations.", "source": "tools"}
{"id": "ca_009", "domain": "crew_ai_expert", "difficulty": "easy", "question": "What is MCP integration in CrewAI tools?", "ground_truth": "MCP (Model Context Protocol) integration allows CrewAI to seamlessly integrate with external tool standards and services, extending the framework's capability to work with diverse tool ecosystems.", "source": "tools"}
{"id": "ca_010", "domain": "crew_ai_expert", "difficulty": "easy", "question": "What is agentic RAG and how does it relate to CrewAI knowledge?", "ground_truth": "Agentic RAG (Retrieval-Augmented Generation) in CrewAI's knowledge system enables agents to dynamically retrieve and reason over knowledge sources, enhancing their ability to provide informed and accurate responses.", "source": "knowledge"}
{"id": "ca_011", "domain": "crew_ai_expert", "difficulty": "easy", "question": "Name the four types of memory supported by CrewAI.", "ground_truth": "CrewAI supports short-term memory (current session), long-term memory (persistent storage), entity memory (tracking entities and relationships), and contextual memory (context-aware information retrieval).", "source": "memory"}
{"id": "ca_012", "domain": "crew_ai_expert", "difficulty": "easy", "question": "What is LanceDB's role in CrewAI memory?", "ground_truth": "LanceDB is the vector database backend that powers CrewAI's memory system, enabling efficient storage and retrieval of embeddings for agent memory operations.", "source": "memory"}
{"id": "ca_013", "domain": "crew_ai_expert", "difficulty": "easy", "question": "What is a planning agent in CrewAI?", "ground_truth": "A planning agent in CrewAI is a specialized agent responsible for breaking down complex tasks, creating execution plans, and coordinating the workflow of other agents.", "source": "planning"}
{"id": "ca_014", "domain": "crew_ai_expert", "difficulty": "easy", "question": "What does async execution mean in CrewAI tasks?", "ground_truth": "Async execution allows tasks to run concurrently or non-sequentially, enabling parallel processing and improved performance when multiple tasks do not have dependencies.", "source": "tasks"}
{"id": "ca_015", "domain": "crew_ai_expert", "difficulty": "easy", "question": "What is the purpose of the CrewAI CLI?", "ground_truth": "The CrewAI CLI provides command-line tools for creating, managing, training, testing, and deploying CrewAI projects and agents.", "source": "cli"}
{"id": "ca_016", "domain": "crew_ai_expert", "difficulty": "easy", "question": "What are event listeners in CrewAI and why are they important?", "ground_truth": "Event listeners are mechanisms that monitor and respond to events during crew execution, enabling logging, monitoring, and custom actions at different execution stages.", "source": "event_listeners"}
{"id": "ca_017", "domain": "crew_ai_expert", "difficulty": "easy", "question": "Name three observability platforms that CrewAI supports.", "ground_truth": "CrewAI supports Langfuse, Datadog, and MLflow for observability and monitoring of agent and crew performance.", "source": "observability"}
{"id": "ca_018", "domain": "crew_ai_expert", "difficulty": "easy", "question": "What is reasoning in CrewAI agents?", "ground_truth": "Reasoning in CrewAI refers to the agent's capability to think through problems systematically, weigh options, and make informed decisions based on available information and constraints.", "source": "reasoning"}
{"id": "ca_019", "domain": "crew_ai_expert", "difficulty": "easy", "question": "How do you create a custom tool in CrewAI?", "ground_truth": "Custom tools in CrewAI are created by defining a tool class or function that performs a specific operation, which can then be assigned to agents to extend their capabilities.", "source": "tools"}
{"id": "ca_020", "domain": "crew_ai_expert", "difficulty": "easy", "question": "What is production architecture in CrewAI?", "ground_truth": "Production architecture in CrewAI refers to best practices and patterns for deploying crews at scale, including considerations for reliability, monitoring, security, and performance optimization.", "source": "production_architecture"}
{"id": "ca_021", "domain": "crew_ai_expert", "difficulty": "medium", "question": "How do role-based agent designs in CrewAI differ from generic LLM agents, and what specific attributes define an agent's role?", "ground_truth": "Role-based agents in CrewAI have explicit role definitions (e.g., researcher, manager, worker) that shape their behavior through attributes like role description, goal, and backstory. These attributes prime the LLM to adopt specific personas and decision-making patterns, unlike generic agents that lack this structured role context.", "source": "agents_role_design"}
{"id": "ca_022", "domain": "crew_ai_expert", "difficulty": "medium", "question": "What are the key differences between sequential and hierarchical process flows in CrewAI crews, and when would you choose each?", "ground_truth": "Sequential processes execute tasks one after another in defined order, suitable for linear workflows. Hierarchical processes use a manager agent to delegate and coordinate work among worker agents, ideal for complex problems requiring adaptive task delegation and parallel subtask execution.", "source": "crews_processes"}
{"id": "ca_023", "domain": "crew_ai_expert", "difficulty": "medium", "question": "Explain how task guardrails work in CrewAI and their role in ensuring output quality and safety.", "ground_truth": "Task guardrails are constraints and validation rules applied to task execution that ensure outputs meet defined criteria (e.g., format requirements, safety checks, content filtering). They prevent agents from producing non-compliant outputs and can trigger retries or alternative execution paths when guardrails are violated.", "source": "tasks_guardrails"}
{"id": "ca_024", "domain": "crew_ai_expert", "difficulty": "medium", "question": "How does async task execution in CrewAI improve performance, and what architectural considerations must be made?", "ground_truth": "Async task execution allows multiple tasks to run concurrently rather than sequentially, reducing total execution time when tasks have no dependencies. This requires careful management of shared state, output dependencies between tasks, and error handling to ensure consistency across parallel execution paths.", "source": "tasks_async_execution"}
{"id": "ca_025", "domain": "crew_ai_expert", "difficulty": "medium", "question": "What is the relationship between event-driven workflows in CrewAI Flows and traditional sequential crew execution?", "ground_truth": "Flows enable event-driven workflows where execution paths are determined by runtime events and state transitions, offering more flexibility than sequential crews. Flows are designed for complex, non-linear processes where task execution depends on external events or conditional logic rather than a predefined linear sequence.", "source": "flows_event_driven"}
{"id": "ca_026", "domain": "crew_ai_expert", "difficulty": "medium", "question": "How does state management in CrewAI Flows differ from crew-based state handling?", "ground_truth": "Flows use explicit state management where state is stored, updated, and passed between workflow nodes, allowing complex branching logic and conditional transitions. Crews rely on sequential task chaining where state flows implicitly through task outputs, offering less explicit state control.", "source": "flows_state_management"}
{"id": "ca_027", "domain": "crew_ai_expert", "difficulty": "medium", "question": "What advantages do the 100+ built-in CrewAI tools provide compared to custom tool development, and when would you develop custom tools?", "ground_truth": "Built-in tools provide pre-integrated, tested functionality for common operations (API calls, file handling, web search, etc.) without custom development overhead. Custom tools are needed for domain-specific operations, proprietary systems, or workflows that built-in tools cannot cover, allowing extensibility for specialized use cases.", "source": "tools_builtin_custom"}
{"id": "ca_028", "domain": "crew_ai_expert", "difficulty": "medium", "question": "How does MCP integration in CrewAI expand tool capabilities, and what is the integration pattern?", "ground_truth": "MCP (Model Context Protocol) integration allows CrewAI agents to access external tool ecosystems and services through a standardized protocol, expanding tool availability beyond built-in offerings. Agents can dynamically discover and use MCP-compatible tools, enabling integration with third-party platforms and services.", "source": "tools_mcp_integration"}
{"id": "ca_029", "domain": "crew_ai_expert", "difficulty": "medium", "question": "What is agentic RAG in CrewAI's Knowledge feature, and how does it differ from traditional retrieval-augmented generation?", "ground_truth": "Agentic RAG empowers agents to autonomously decide when and how to retrieve relevant knowledge from a knowledge base, rather than passively receiving retrieved documents. Agents evaluate context, formulate retrieval queries, and iteratively refine knowledge retrieval, enabling more intelligent and adaptive information gathering.", "source": "knowledge_agentic_rag"}
{"id": "ca_030", "domain": "crew_ai_expert", "difficulty": "medium", "question": "Describe the differences between short-term, long-term, entity, and contextual memory in CrewAI, and their respective use cases.", "ground_truth": "Short-term memory stores recent interactions and context within a task/session; long-term memory persists information across sessions; entity memory tracks specific entities and relationships; contextual memory captures decision context and reasoning. Each serves different purposes: short-term for immediate context, long-term for learning over time, entity for knowledge graphs, contextual for interpretability.", "source": "memory_types"}
{"id": "ca_031", "domain": "crew_ai_expert", "difficulty": "medium", "question": "How does LanceDB backing in CrewAI memory systems enable scalable and efficient memory management?", "ground_truth": "LanceDB provides vector storage and semantic search capabilities that allow CrewAI's memory systems to efficiently store, index, and retrieve large volumes of memories using semantic similarity rather than exact matching. This enables scalable memory operations with fast retrieval times even with millions of stored memories.", "source": "memory_lancedb"}
{"id": "ca_032", "domain": "crew_ai_expert", "difficulty": "medium", "question": "What is the Planning Agent in CrewAI, and how does it influence crew execution and task orchestration?", "ground_truth": "The Planning Agent is a specialized agent that generates execution plans before task execution begins, breaking down complex goals into structured subtasks with dependencies and optimal ordering. It improves crew efficiency by preventing redundant work, identifying parallelizable tasks, and ensuring agents have clear execution strategies.", "source": "planning_agent"}
{"id": "ca_033", "domain": "crew_ai_expert", "difficulty": "medium", "question": "How does reasoning capability in CrewAI enhance agent decision-making, and what reasoning patterns are supported?", "ground_truth": "Reasoning capabilities enable agents to think through problems step-by-step, consider multiple approaches, and justify decisions before taking action. CrewAI supports chain-of-thought reasoning, multi-step problem decomposition, and constraint-based reasoning, improving output quality and agent transparency.", "source": "reasoning_patterns"}
{"id": "ca_034", "domain": "crew_ai_expert", "difficulty": "medium", "question": "What are the key differences between training and testing workflows in CrewAI, and how do they support iterative improvement?", "ground_truth": "Training workflows involve fine-tuning agents and crews on task examples to improve performance, while testing workflows validate behavior against benchmarks and test cases. Together, they enable iterative refinement: training improves agent capabilities, testing validates improvements, and results guide further training adjustments.", "source": "training_testing"}
{"id": "ca_035", "domain": "crew_ai_expert", "difficulty": "medium", "question": "How does the CrewAI CLI facilitate development and deployment workflows, and what key commands support crew management?", "ground_truth": "The CrewAI CLI provides commands for project scaffolding, agent/crew/task creation, testing, and deployment. Key commands enable rapid project setup, configuration management, and local testing before production deployment, streamlining the development lifecycle from initialization to deployment.", "source": "cli_commands"}
{"id": "ca_036", "domain": "crew_ai_expert", "difficulty": "medium", "question": "What role do event listeners play in CrewAI production architecture, and how do they enable observability?", "ground_truth": "Event listeners capture and react to execution events (task starts, completions, errors, etc.) throughout crew execution, enabling real-time monitoring, logging, and debugging. They provide hooks for custom actions (notifications, metrics collection, error handling) without modifying core crew logic.", "source": "event_listeners"}
{"id": "ca_037", "domain": "crew_ai_expert", "difficulty": "medium", "question": "How does Langfuse integration in CrewAI observability enable tracing of multi-agent workflows?", "ground_truth": "Langfuse integration automatically captures detailed traces of agent interactions, tool usage, and decision-making within multi-agent workflows, providing visibility into execution flow, latency, costs, and errors. These traces enable debugging, performance analysis, and optimization of crew behavior.", "source": "observability_langfuse"}
{"id": "ca_038", "domain": "crew_ai_expert", "difficulty": "medium", "question": "What metrics and insights does Datadog integration provide for CrewAI production monitoring?", "ground_truth": "Datadog integration enables monitoring of crew execution metrics (success/failure rates, latency, resource usage), agent performance (tool usage patterns, reasoning time), and system health. It provides dashboards, alerts, and correlations between crew metrics and infrastructure performance for comprehensive production monitoring.", "source": "observability_datadog"}
{"id": "ca_039", "domain": "crew_ai_expert", "difficulty": "medium", "question": "How does MLflow integration support experiment tracking and model management in CrewAI training workflows?", "ground_truth": "MLflow integration tracks training experiments, logs model parameters, metrics, and artifacts, enabling reproducibility and comparative analysis across training runs. It supports hyperparameter tuning, model versioning, and deployment integration, streamlining the full lifecycle of agent model management.", "source": "observability_mlflow"}
{"id": "ca_040", "domain": "crew_ai_expert", "difficulty": "medium", "question": "What are the critical architectural decisions when designing a production CrewAI system, considering scalability, reliability, and observability?", "ground_truth": "Critical decisions include: choosing crew process type (sequential vs. hierarchical) based on complexity; implementing async task execution for parallelization; selecting memory backends (LanceDB) for scalability; configuring resilience (retries, error handling, guardrails); integrating observability tools (Langfuse, Datadog) for monitoring; and designing state management for consistency across distributed execution.", "source": "production_architecture"}
{"id": "ca_041", "domain": "crew_ai_expert", "difficulty": "hard", "question": "When designing a hierarchical crew process with a manager agent, what are the critical considerations for preventing infinite delegation loops, and how does CrewAI's hierarchical process differ from sequential process in handling agent failures?", "ground_truth": "Hierarchical processes use a manager agent to coordinate workers and make decisions about task delegation. Prevention of infinite loops requires explicit task completion criteria and manager guardrails. Unlike sequential processes where failure stops execution, hierarchical processes allow the manager to reassign tasks or escalate issues, but require careful definition of maximum delegation depth and fallback strategies.", "source": "Hierarchical_Processes_and_Manager_Coordination"}
{"id": "ca_042", "domain": "crew_ai_expert", "difficulty": "hard", "question": "Explain the architectural differences between short-term memory, long-term memory, and entity memory in CrewAI's memory system, and when would you choose LanceDB-backed contextual memory over in-memory storage for a production multi-agent system handling high-frequency tasks.", "ground_truth": "Short-term memory stores recent interactions per task/agent, long-term memory persists knowledge across sessions in vectors, entity memory tracks relationships between entities, and contextual memory combines these with semantic search via LanceDB. For production high-frequency systems, LanceDB is preferred because it provides persistent vector storage, scales horizontally, enables efficient semantic search, and prevents token bloat from accumulated context.", "source": "Memory_Architecture_and_LanceDB_Integration"}
{"id": "ca_043", "domain": "crew_ai_expert", "difficulty": "hard", "question": "In a flow-based architecture with event-driven state management, how would you implement error recovery across multiple parallel events without causing state inconsistency, and what are the implications for observability when using Langfuse integration?", "ground_truth": "Event-driven flows require idempotent event handlers and transactional state updates to prevent inconsistency during parallel execution. Use Langfuse's trace context to correlate events across parallel branches, capture state snapshots at each event boundary, and implement compensating transactions for rollback scenarios. State versioning and event sourcing patterns help maintain consistency while providing full observability of state transitions.", "source": "Event_Driven_Flows_and_State_Management"}
{"id": "ca_044", "domain": "crew_ai_expert", "difficulty": "hard", "question": "When implementing agentic RAG with CrewAI's knowledge system, what are the performance implications of synchronous versus asynchronous knowledge retrieval, and how does the planning agent optimize knowledge selection across multiple heterogeneous knowledge sources?", "ground_truth": "Synchronous RAG blocks task execution during retrieval, while async retrieval allows parallel processing and better resource utilization. The planning agent optimizes by evaluating query relevance against knowledge source metadata, selecting optimal source combinations, and batching retrieval requests. Performance depends on knowledge indexing strategy (embedding model, vector DB choice) and source routing logic implemented in agent prompts.", "source": "Agentic_RAG_and_Knowledge_Optimization"}
{"id": "ca_045", "domain": "crew_ai_expert", "difficulty": "hard", "question": "Design a custom MCP (Model Context Protocol) integration for a specialized domain and explain how you would handle schema validation, versioning, and fallback mechanisms if the MCP tool becomes unavailable during crew execution.", "ground_truth": "Custom MCP tools require implementing the MCP protocol with defined input/output schemas validated against JSONSchema. For versioning, maintain API version compatibility and deprecation paths in tool metadata. Fallback mechanisms include: graceful degradation with alternative tools, retry logic with exponential backoff, and circuit breaker patterns that disable unavailable MCPs while allowing crew continuation. Wrap MCPs in try-except blocks with proper error propagation.", "source": "Custom_Tools_and_MCP_Integration"}
{"id": "ca_046", "domain": "crew_ai_expert", "difficulty": "hard", "question": "In a production environment using Datadog observability, how would you instrument a multi-agent crew to capture latency bottlenecks at the task level, detect agent-to-agent communication failures, and correlate performance degradation with LLM API rate limiting?", "ground_truth": "Use Datadog APM to instrument crew.kickoff() and task.execute() methods with custom spans. Capture task duration, agent switching overhead, and LLM call timing. Implement custom metrics for rate limit detection via LLM response headers and task retry counts. Correlate traces across agents using distributed context IDs. Set up Datadog monitors for p95/p99 latencies and alert on rate limit 429 responses.", "source": "Datadog_Observability_and_Performance_Instrumentation"}
{"id": "ca_047", "domain": "crew_ai_expert", "difficulty": "hard", "question": "What are the security implications of using agent_executor.verify_tool_use=False in a multi-tenant environment, and how would you implement task-level access control to prevent one agent's task from accessing another tenant's knowledge base or tool outputs?", "ground_truth": "Disabling tool verification removes safety checks and enables arbitrary tool execution, creating security risks in multi-tenant systems. Implement task-level access control through: (1) tenant-scoped tool decorators that validate agent identity, (2) knowledge base filtering via tenant ID in RAG queries, (3) output sanitization between task handoffs, and (4) role-based access control in agent definitions with tenant context. Always validate tool access within tool implementation.", "source": "Security_and_Multi_Tenant_Task_Isolation"}
{"id": "ca_048", "domain": "crew_ai_expert", "difficulty": "hard", "question": "Explain the interaction between CrewAI's reasoning engine and the planning agent when handling ambiguous user requests, including how you would tune reasoning depth to balance accuracy versus token consumption in cost-sensitive deployments.", "ground_truth": "The reasoning engine enables step-by-step thinking via extended reasoning models, while the planning agent decomposes complex requests into task sequences. For ambiguous requests, set reasoning=True on the planning agent to explore multiple interpretations before task creation. Control token consumption by limiting reasoning tokens per task, using cached reasoning for repeated patterns, and applying the planning agent selectively to non-routine requests only.", "source": "Reasoning_and_Planning_Agent_Tuning"}
{"id": "ca_049", "domain": "crew_ai_expert", "difficulty": "hard", "question": "When training a crew on domain-specific tasks using the training framework, what metrics would you use to detect overfitting to training data, and how would you structure a validation pipeline to ensure agents generalize across unseen task variations?", "ground_truth": "Monitor training loss, validation loss (on holdout set), and domain-specific metrics like task completion accuracy and answer relevance. Detect overfitting via validation loss plateau while training loss decreases. Use stratified cross-validation across task types and create synthetic task variations using paraphrasing and domain perturbations. Implement A/B testing in production with traffic splitting to validate generalization before full rollout.", "source": "Training_Framework_and_Validation"}
{"id": "ca_050", "domain": "crew_ai_expert", "difficulty": "hard", "question": "Design a disaster recovery strategy for a CrewAI deployment where crews are executing long-running async tasks with state stored in LanceDB. What checkpoint and resumption mechanisms would you implement, and how would you handle partial task execution recovery?", "ground_truth": "Implement checkpointing at task boundaries with state snapshots stored in LanceDB alongside execution logs. For async tasks, persist task context, agent state, and current tool outputs before each LLM call. On recovery, replay checkpoint to resume from last completed state rather than task start. Use idempotent tool operations and transaction IDs to prevent duplicate actions. Implement dead letter queues for permanently failed tasks with manual intervention workflows.", "source": "Async_Tasks_and_Disaster_Recovery"}
