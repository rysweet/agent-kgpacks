[
  {
    "id": "aa_001",
    "domain": "azure_ai_foundry",
    "difficulty": "easy",
    "question": "How many models are available in the Azure AI Foundry model catalog?",
    "ground_truth": "Azure AI Foundry provides access to over 1900 models from providers including OpenAI, Meta, Mistral, and Anthropic.",
    "source": "model_catalog"
  },
  {
    "id": "aa_002",
    "domain": "azure_ai_foundry",
    "difficulty": "easy",
    "question": "What are the two main types of flows supported by Prompt Flow in Azure AI Foundry?",
    "ground_truth": "Prompt Flow supports standard flows and chat flows for developing and deploying LLM applications.",
    "source": "prompt_flow"
  },
  {
    "id": "aa_003",
    "domain": "azure_ai_foundry",
    "difficulty": "easy",
    "question": "Name two compute options available for fine-tuning models in Azure AI Foundry.",
    "ground_truth": "Azure AI Foundry offers serverless compute and managed compute options for fine-tuning models.",
    "source": "fine_tuning"
  },
  {
    "id": "aa_004",
    "domain": "azure_ai_foundry",
    "difficulty": "easy",
    "question": "What is the primary purpose of the Foundry Agent Service?",
    "ground_truth": "The Foundry Agent Service enables multi-agent orchestration and knowledge integration for enterprise AI operations.",
    "source": "agent_service"
  },
  {
    "id": "aa_005",
    "domain": "azure_ai_foundry",
    "difficulty": "easy",
    "question": "What are the two types of fine-tuning methods supported in Azure AI Foundry?",
    "ground_truth": "Azure AI Foundry supports Supervised Fine-Tuning (SFT) and Reinforcement Fine-Tuning (RFT) methods.",
    "source": "fine_tuning"
  },
  {
    "id": "aa_006",
    "domain": "azure_ai_foundry",
    "difficulty": "easy",
    "question": "Which deployment model allows you to deploy Prompt Flow applications as API endpoints?",
    "ground_truth": "Prompt Flow applications can be deployed as standard endpoints, serverless API endpoints, or on managed compute.",
    "source": "deployments"
  },
  {
    "id": "aa_007",
    "domain": "azure_ai_foundry",
    "difficulty": "easy",
    "question": "What is the primary function of the evaluations feature in Azure AI Foundry?",
    "ground_truth": "The evaluations feature provides agent evaluation SDK and continuous monitoring capabilities for assessing AI application performance.",
    "source": "evaluations"
  },
  {
    "id": "aa_008",
    "domain": "azure_ai_foundry",
    "difficulty": "easy",
    "question": "Name the three-step framework for responsible AI governance in Azure AI Foundry.",
    "ground_truth": "The discover-protect-govern framework is used for responsible AI implementation in Azure AI Foundry.",
    "source": "responsible_ai"
  },
  {
    "id": "aa_009",
    "domain": "azure_ai_foundry",
    "difficulty": "easy",
    "question": "What security feature in Azure AI Foundry restricts network access to private networks?",
    "ground_truth": "Private Link networking enables secure, private connections to Azure AI Foundry resources.",
    "source": "networking"
  },
  {
    "id": "aa_010",
    "domain": "azure_ai_foundry",
    "difficulty": "easy",
    "question": "Which access control model does Azure AI Foundry use for managing permissions?",
    "ground_truth": "Azure AI Foundry uses Role-Based Access Control (RBAC) for managing user permissions and resource access.",
    "source": "rbac"
  },
  {
    "id": "aa_011",
    "domain": "azure_ai_foundry",
    "difficulty": "easy",
    "question": "Name at least two programming languages supported by Azure AI Foundry SDK.",
    "ground_truth": "Azure AI Foundry SDK is available in Python, C#, TypeScript, and Java.",
    "source": "sdk_integration"
  },
  {
    "id": "aa_012",
    "domain": "azure_ai_foundry",
    "difficulty": "easy",
    "question": "What content safety feature is part of the responsible AI capabilities in Azure AI Foundry?",
    "ground_truth": "Content safety detection is a key responsible AI feature that helps identify and filter harmful content.",
    "source": "responsible_ai"
  },
  {
    "id": "aa_013",
    "domain": "azure_ai_foundry",
    "difficulty": "easy",
    "question": "Which OpenAI models can be accessed through the Azure AI Foundry model catalog?",
    "ground_truth": "OpenAI models are available in the Azure AI Foundry model catalog along with other major provider models.",
    "source": "model_catalog"
  },
  {
    "id": "aa_014",
    "domain": "azure_ai_foundry",
    "difficulty": "easy",
    "question": "What does Prompt Flow enable developers to do?",
    "ground_truth": "Prompt Flow enables developers to build, test, and deploy LLM applications using standard or chat flow templates.",
    "source": "prompt_flow"
  },
  {
    "id": "aa_015",
    "domain": "azure_ai_foundry",
    "difficulty": "easy",
    "question": "True or False: Azure AI Foundry replaces the previous Microsoft Foundry branding.",
    "ground_truth": "True. Azure AI Foundry is the current unified platform, previously known as Microsoft Foundry.",
    "source": "platform_overview"
  },
  {
    "id": "aa_016",
    "domain": "azure_ai_foundry",
    "difficulty": "easy",
    "question": "What models are provided by Mistral in the Azure AI Foundry catalog?",
    "ground_truth": "Mistral models are available in the Azure AI Foundry model catalog alongside OpenAI, Meta, and Anthropic offerings.",
    "source": "model_catalog"
  },
  {
    "id": "aa_017",
    "domain": "azure_ai_foundry",
    "difficulty": "easy",
    "question": "What is the primary advantage of serverless compute for fine-tuning in Azure AI Foundry?",
    "ground_truth": "Serverless compute provides on-demand, scalable fine-tuning without requiring infrastructure management.",
    "source": "fine_tuning"
  },
  {
    "id": "aa_018",
    "domain": "azure_ai_foundry",
    "difficulty": "easy",
    "question": "How does Azure AI Foundry support enterprise AI operations?",
    "ground_truth": "Azure AI Foundry is a unified platform that integrates model access, deployment, evaluation, and responsible AI governance for enterprise AI operations.",
    "source": "platform_overview"
  },
  {
    "id": "aa_019",
    "domain": "azure_ai_foundry",
    "difficulty": "easy",
    "question": "What is the purpose of the agent evaluation SDK in Azure AI Foundry?",
    "ground_truth": "The agent evaluation SDK enables performance assessment and quality evaluation of multi-agent systems deployed in Azure AI Foundry.",
    "source": "evaluations"
  },
  {
    "id": "aa_020",
    "domain": "azure_ai_foundry",
    "difficulty": "easy",
    "question": "Which deployment option in Azure AI Foundry provides API-based access without managing infrastructure?",
    "ground_truth": "Serverless API deployment option provides managed, scalable API endpoints without infrastructure management.",
    "source": "deployments"
  },
  {
    "id": "aa_021",
    "domain": "azure_ai_foundry",
    "difficulty": "medium",
    "question": "When deploying a custom fine-tuned model in Azure AI Foundry, what are the key differences between serverless API and managed compute deployment options in terms of scaling and cost management?",
    "ground_truth": "Serverless API deployments auto-scale based on demand with pay-per-token pricing, ideal for variable workloads. Managed compute deployments require pre-allocated compute instances with fixed costs, suitable for predictable, consistent throughput needs.",
    "source": "deployments_options"
  },
  {
    "id": "aa_022",
    "domain": "azure_ai_foundry",
    "difficulty": "medium",
    "question": "In Prompt Flow, what is the structural difference between a standard flow and a chat flow, and when should you use each?",
    "ground_truth": "Standard flows process single inputs with linear logic, ideal for batch processing or one-shot tasks. Chat flows maintain conversation history and state, supporting multi-turn interactions with memory, making them suitable for conversational AI applications.",
    "source": "prompt_flow_types"
  },
  {
    "id": "aa_023",
    "domain": "azure_ai_foundry",
    "difficulty": "medium",
    "question": "How does the discover-protect-govern framework in Responsible AI address content safety in Azure AI Foundry deployments?",
    "ground_truth": "Discover identifies harmful content risks, protect implements content filters and safety guardrails before deployment, and govern enforces monitoring and compliance policies post-deployment for continuous safety assurance.",
    "source": "responsible_ai_framework"
  },
  {
    "id": "aa_024",
    "domain": "azure_ai_foundry",
    "difficulty": "medium",
    "question": "When configuring a multi-agent system using Foundry Agent Service, what role does knowledge integration play in agent decision-making?",
    "ground_truth": "Knowledge integration provides agents with access to curated data sources and context, enabling informed decisions and reducing hallucinations. Agents can query integrated knowledge bases to ground responses in factual information during orchestration.",
    "source": "foundry_agent_service"
  },
  {
    "id": "aa_025",
    "domain": "azure_ai_foundry",
    "difficulty": "medium",
    "question": "Explain the trade-offs between supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT) in Azure AI Foundry when optimizing model behavior.",
    "ground_truth": "SFT requires labeled examples and directly teaches desired outputs, faster and simpler but less flexible. RFT uses reward signals to shape behavior iteratively, enabling nuanced optimization but requiring more data and computational resources.",
    "source": "fine_tuning_methods"
  },
  {
    "id": "aa_026",
    "domain": "azure_ai_foundry",
    "difficulty": "medium",
    "question": "How does private link networking enhance security in Azure AI Foundry, and what scenarios would require its implementation?",
    "ground_truth": "Private link establishes encrypted, private connections to Azure AI Foundry endpoints without traversing public internet, preventing data exposure. It's required for regulated industries (healthcare, finance) or organizations with strict data residency and network isolation policies.",
    "source": "private_link_networking"
  },
  {
    "id": "aa_027",
    "domain": "azure_ai_foundry",
    "difficulty": "medium",
    "question": "What is the primary advantage of using the model catalog with 1900+ models from multiple vendors, and how does this affect deployment strategy?",
    "ground_truth": "The extensive model catalog enables teams to compare and select from diverse architectures (OpenAI, Meta, Mistral, Anthropic) based on specific use cases, latency, cost, and performance requirements. This flexibility allows optimized model selection without vendor lock-in.",
    "source": "model_catalog"
  },
  {
    "id": "aa_028",
    "domain": "azure_ai_foundry",
    "difficulty": "medium",
    "question": "In Azure AI Foundry's RBAC implementation, how would you design permissions to allow data scientists to fine-tune models but prevent them from deploying to production endpoints?",
    "ground_truth": "Assign data scientists the 'AI Developer' or custom role with fine-tuning permissions but exclude 'Deployment Manager' or deployment-specific roles. Use resource group or subscription-level RBAC policies to segregate development and production environments.",
    "source": "rbac_configuration"
  },
  {
    "id": "aa_029",
    "domain": "azure_ai_foundry",
    "difficulty": "medium",
    "question": "How does the agent evaluation SDK in Azure AI Foundry differ from standard model evaluation, and what specific metrics does it track?",
    "ground_truth": "Agent evaluation SDK assesses end-to-end agent behavior including planning, tool execution, and multi-step reasoning, beyond single-model outputs. It tracks metrics like task completion rate, step efficiency, hallucination frequency, and knowledge retrieval accuracy.",
    "source": "agent_evaluation_sdk"
  },
  {
    "id": "aa_030",
    "domain": "azure_ai_foundry",
    "difficulty": "medium",
    "question": "When deploying a Prompt Flow application as an endpoint, what considerations must you account for regarding response latency and concurrent request handling?",
    "ground_truth": "Consider the flow complexity, number of LLM calls, and external API dependencies affecting latency. For concurrent requests, choose between serverless (auto-scaling) or managed compute (fixed instances), and configure appropriate timeout and retry policies.",
    "source": "prompt_flow_deployment"
  },
  {
    "id": "aa_031",
    "domain": "azure_ai_foundry",
    "difficulty": "medium",
    "question": "How would you integrate Azure AI Foundry capabilities into a Python application using the SDK, and what authentication patterns are recommended?",
    "ground_truth": "Use the Python SDK to authenticate via managed identity, connection strings, or API keys. Import required modules (azure.ai.foundry), initialize clients for deployments, fine-tuning, or evaluations, and manage credentials through environment variables or credential providers.",
    "source": "sdk_python_integration"
  },
  {
    "id": "aa_032",
    "domain": "azure_ai_foundry",
    "difficulty": "medium",
    "question": "Describe how continuous monitoring in Azure AI Foundry helps maintain responsible AI standards post-deployment.",
    "ground_truth": "Continuous monitoring tracks model drift, content safety violations, performance degradation, and bias indicators over time. Alerts trigger when thresholds are exceeded, enabling proactive mitigation and compliance audit trails.",
    "source": "continuous_monitoring"
  },
  {
    "id": "aa_033",
    "domain": "azure_ai_foundry",
    "difficulty": "medium",
    "question": "When designing a chat flow in Prompt Flow, how do you manage context window limitations while maintaining conversation quality across multi-turn interactions?",
    "ground_truth": "Implement conversation history summarization, sliding window techniques, or semantic compression to retain key context while staying within token limits. Configure flow logic to prioritize recent messages and use retrieval-augmented generation for historical context.",
    "source": "prompt_flow_chat_design"
  },
  {
    "id": "aa_034",
    "domain": "azure_ai_foundry",
    "difficulty": "medium",
    "question": "What is the relationship between model fine-tuning and deployment in Azure AI Foundry, and how do version management workflows ensure reproducibility?",
    "ground_truth": "Fine-tuned models generate versioned artifacts stored in the catalog. Each version links to training parameters, data, and hyperconfigs. Deployments reference specific model versions, enabling rollback and A/B testing across versions.",
    "source": "fine_tuning_deployment_workflow"
  },
  {
    "id": "aa_035",
    "domain": "azure_ai_foundry",
    "difficulty": "medium",
    "question": "How does serverless compute for fine-tuning in Azure AI Foundry reduce operational overhead compared to managed compute alternatives?",
    "ground_truth": "Serverless fine-tuning abstracts infrastructure management, auto-scales compute resources, and charges only for compute time used. Managed compute requires manual scaling configuration and fixed cost allocation, increasing overhead.",
    "source": "fine_tuning_serverless"
  },
  {
    "id": "aa_036",
    "domain": "azure_ai_foundry",
    "difficulty": "medium",
    "question": "In a multi-agent orchestration scenario using Foundry Agent Service, how do you prevent agent conflicts and ensure coordinated decision-making?",
    "ground_truth": "Use central orchestration logic to assign roles and responsibilities to agents, implement shared knowledge bases for consensus, define escalation paths for conflicting decisions, and apply workflow policies that enforce coordination rules.",
    "source": "multi_agent_orchestration"
  },
  {
    "id": "aa_037",
    "domain": "azure_ai_foundry",
    "difficulty": "medium",
    "question": "When implementing content safety using Azure AI Foundry's responsible AI tools, what are the trade-offs between strict filtering and user experience?",
    "ground_truth": "Strict filtering maximizes safety but risks false positives, blocking legitimate requests and degrading UX. Balanced policies use tiered severity levels and user overrides, requiring tuning to match organizational risk tolerance.",
    "source": "content_safety_tradeoffs"
  },
  {
    "id": "aa_038",
    "domain": "azure_ai_foundry",
    "difficulty": "medium",
    "question": "How would you use the TypeScript SDK to monitor and trigger automated responses to evaluation metrics breaches in a deployed Azure AI Foundry application?",
    "ground_truth": "Initialize the TypeScript SDK with evaluation clients, set up metric thresholds, implement listeners for evaluation results, and trigger automated responses (alerts, rollbacks, or retraining) based on breach conditions through webhook or scheduled job mechanisms.",
    "source": "sdk_typescript_monitoring"
  },
  {
    "id": "aa_039",
    "domain": "azure_ai_foundry",
    "difficulty": "medium",
    "question": "What architectural decisions must you make when choosing between deploying multiple specialized models versus a single fine-tuned general model in Azure AI Foundry?",
    "ground_truth": "Specialized models offer better performance per task but increase operational complexity and cost. A single fine-tuned model reduces overhead but may compromise task-specific accuracy. Decision depends on latency SLAs, domain diversity, and maintenance capacity.",
    "source": "model_deployment_architecture"
  },
  {
    "id": "aa_040",
    "domain": "azure_ai_foundry",
    "difficulty": "medium",
    "question": "How do you configure RBAC and private link networking together to create a secure, compliant environment for sensitive enterprise AI workloads in Azure AI Foundry?",
    "ground_truth": "Combine RBAC to restrict access by role/identity with private link to isolate network traffic. Place resources in a VNet, disable public endpoints, use managed identities for authentication, and audit access logs to meet compliance requirements.",
    "source": "security_rbac_networking"
  },
  {
    "id": "aa_041",
    "domain": "azure_ai_foundry",
    "difficulty": "hard",
    "question": "When fine-tuning a model using reinforcement learning from human feedback (RLHF) in Azure AI Foundry, what are the key architectural differences between serverless and managed compute approaches, and when would you choose one over the other for production workloads?",
    "ground_truth": "Serverless compute provides on-demand scaling without infrastructure management but has latency overhead and cost per compute unit; managed compute offers dedicated resources, lower per-token costs, and predictable performance but requires capacity planning. Choose serverless for variable, bursty workloads with cost sensitivity; choose managed compute for sustained, high-throughput production fine-tuning requiring SLA guarantees.",
    "source": "fine_tuning_compute_options"
  },
  {
    "id": "aa_042",
    "domain": "azure_ai_foundry",
    "difficulty": "hard",
    "question": "In a multi-agent orchestration scenario using Foundry Agent Service, how would you design fault tolerance and retry logic when one agent fails to call a knowledge integration endpoint, while ensuring the workflow doesn't cascade failures to dependent agents?",
    "ground_truth": "Implement circuit breaker patterns at the agent orchestration layer with configurable retry policies (exponential backoff), set timeout thresholds per agent call, use health checks for knowledge endpoints before routing, and design fallback paths that reroute to alternative agents or cached knowledge rather than propagating errors upstream to dependent agents.",
    "source": "agent_service_orchestration"
  },
  {
    "id": "aa_043",
    "domain": "azure_ai_foundry",
    "difficulty": "hard",
    "question": "When deploying an LLM application via Prompt Flow as a managed compute endpoint, what are the security implications of model weights, prompt templates, and input data at rest and in transit, and how do Private Link networking and RBAC interact to mitigate these risks?",
    "ground_truth": "Model weights and prompt logic are stored in managed storage with encryption at rest; data in transit uses TLS 1.2+. Private Link ensures network traffic never traverses the public internet, reducing DLP risk. RBAC controls who can deploy, invoke, or modify endpoints; combine with managed identity to prevent credential exposure. Separate RBAC roles for deployment vs. inference invocation enforce least-privilege access.",
    "source": "deployment_security_networking"
  },
  {
    "id": "aa_044",
    "domain": "azure_ai_foundry",
    "difficulty": "hard",
    "question": "You are selecting a model from the 1900+ model catalog for a low-latency, cost-sensitive production inference task. Explain the trade-offs between choosing a smaller open-source model (e.g., Mistral 7B) versus a larger proprietary model (e.g., GPT-4), considering latency, accuracy, cost, and deployment options.",
    "ground_truth": "Smaller models (Mistral 7B) offer lower latency, lower inference cost per token, and can be deployed on serverless or managed compute efficiently; trade-off is reduced accuracy and reasoning capability. Larger models (GPT-4) provide superior accuracy and reasoning but incur higher per-token costs and latency. Choose smaller models for latency-critical, cost-optimized workloads; choose larger models when accuracy outweighs cost, or use smaller models with fine-tuning for domain-specific tasks.",
    "source": "model_catalog_selection"
  },
  {
    "id": "aa_045",
    "domain": "azure_ai_foundry",
    "difficulty": "hard",
    "question": "In Prompt Flow, describe how you would architect a standard flow versus a chat flow for a customer support chatbot, including implications for state management, context persistence, and how each design affects evaluation metrics in the Agent Evaluation SDK.",
    "ground_truth": "Standard flows are stateless, process single inputs deterministically, and are ideal for one-off tasks; chat flows maintain conversation history and state across turns. For customer support, use chat flow to preserve context, enabling better follow-up handling. Standard flows are easier to evaluate per-turn; chat flows require conversation-level metrics (coherence across turns, context retention). The Agent Evaluation SDK tracks both turn-level and session-level performance, so chat flows need metrics assessing multi-turn quality.",
    "source": "prompt_flow_architecture"
  },
  {
    "id": "aa_046",
    "domain": "azure_ai_foundry",
    "difficulty": "hard",
    "question": "When implementing the discover-protect-govern framework for responsible AI in Azure AI Foundry, how do content safety policies interact with fine-tuning and deployment, and what happens if a fine-tuned model's outputs violate content safety thresholds during continuous monitoring?",
    "ground_truth": "Content safety is enforced at prompt input and response output layers; during fine-tuning, training data is scanned for harmful content using content filters. If a fine-tuned model generates unsafe outputs detected in production monitoring, the deployment can be automatically throttled or halted based on policy configuration. Govern phase uses discovery metrics to retrain or adjust safety thresholds; protect phase gates deployments until safety benchmarks are met.",
    "source": "responsible_ai_framework"
  },
  {
    "id": "aa_047",
    "domain": "azure_ai_foundry",
    "difficulty": "hard",
    "question": "Explain how RBAC in Azure AI Foundry prevents privilege escalation when multiple teams (data science, ML ops, security) collaborate on a shared model fine-tuning project, and what role assignments would enforce least-privilege separation of duties.",
    "ground_truth": "RBAC uses role definitions (Contributor, Reader, AI Developer, AI Engineer) scoped to resource groups or projects. Separate roles: data scientists as AI Developer (can fine-tune but not deploy), ML Ops as AI Engineer (can deploy and monitor), security as Reader (audit-only). Prevent escalation by ensuring no role includes user/group management permissions; use conditional access policies to enforce MFA for sensitive operations (deployment approval). Regular access reviews detect and revoke excessive permissions.",
    "source": "rbac_access_control"
  },
  {
    "id": "aa_048",
    "domain": "azure_ai_foundry",
    "difficulty": "hard",
    "question": "When integrating the Python SDK with a Prompt Flow endpoint deployed as a serverless API, what are the performance bottlenecks (token limits, concurrency throttling, cold start latency) and how would you design client-side retry and batching strategies to optimize throughput?",
    "ground_truth": "Serverless endpoints have per-request token limits (varies by model, e.g., 4K context) and concurrency throttling based on provisioned capacity. Cold start adds 10-30s latency on first invoke after idle period. Design client batching to pack multiple inputs within token limits, implement exponential backoff retry with jitter for 429 (throttle) responses, use connection pooling in the SDK, and preemptively warm endpoints with health checks. For high throughput, consider switching to managed compute to eliminate cold starts.",
    "source": "sdk_deployment_performance"
  },
  {
    "id": "aa_049",
    "domain": "azure_ai_foundry",
    "difficulty": "hard",
    "question": "In a continuous monitoring scenario using the Agent Evaluation SDK, how would you distinguish between model drift (degraded inference quality) and data drift (changed input distribution), and what remediation actions would each trigger in Azure AI Foundry?",
    "ground_truth": "Model drift is detected via evaluation metrics (accuracy, F1, token edit distance) degrading on held-out test sets; data drift is detected via statistical tests (KS test, Wasserstein distance) on input feature distributions. Model drift triggers fine-tuning retraining or model swaps; data drift may trigger prompt engineering adjustments or retraining with new data distribution. Use the evaluation SDK to log both metrics and input statistics over time; set up alerts for threshold crossings.",
    "source": "continuous_monitoring_evaluation"
  },
  {
    "id": "aa_050",
    "domain": "azure_ai_foundry",
    "difficulty": "hard",
    "question": "Design a multi-region, high-availability architecture for a critical LLM application using Azure AI Foundry across US and EU regions, considering data residency regulations, Private Link connectivity, and cross-region failover for Prompt Flow deployments.",
    "ground_truth": "Deploy separate Azure AI Foundry instances per region for GDPR/data residency compliance. Use managed endpoints in each region with geo-replicated model weights in region-local storage. Connect via Private Link from each region's VNet independently (no cross-region link traversal). Implement DNS-based failover (Azure Traffic Manager) at the application layer, routing requests to healthy regional endpoints. Replicate fine-tuned models and Prompt Flow definitions to each region asynchronously; use timestamp-based consistency checks to prevent stale deployment.",
    "source": "multi_region_deployment_architecture"
  },
  {
    "id": "aa_051",
    "domain": "azure_ai_foundry",
    "difficulty": "hard",
    "question": "When using supervised fine-tuning (SFT) in Azure AI Foundry with a dataset containing imbalanced classes (e.g., 95% negative samples, 5% positive), what are the training pitfalls specific to LLM fine-tuning, and how would you adjust hyperparameters and evaluation metrics to ensure the fine-tuned model generalizes well?",
    "ground_truth": "LLM fine-tuning on imbalanced data leads to output bias toward majority class, reduced minority class recall, and poor calibration. Mitigations: use weighted loss functions (higher weight for minority class), stratified sampling during SFT, adjust learning rate and epoch count to prevent overfitting to majority patterns, use evaluation metrics sensitive to imbalance (F1, precision-recall curves, AUC) rather than accuracy. In Foundry, configure these via fine-tuning job parameters; validate using the evaluation SDK with weighted metrics.",
    "source": "fine_tuning_hyperparameter_optimization"
  }
]
