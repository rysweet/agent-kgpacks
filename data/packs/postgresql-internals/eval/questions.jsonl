{"id": "pi_001", "domain": "postgresql_internals", "difficulty": "easy", "question": "What does MVCC stand for in PostgreSQL, and what is its primary purpose?", "ground_truth": "MVCC stands for Multi-Version Concurrency Control. Its primary purpose is to allow multiple transactions to read different versions of the same row simultaneously without blocking each other, improving concurrency and read performance.", "source": "MVCC"}
{"id": "pi_002", "domain": "postgresql_internals", "difficulty": "easy", "question": "Name the four standard SQL transaction isolation levels supported by PostgreSQL.", "ground_truth": "The four standard isolation levels are: READ UNCOMMITTED, READ COMMITTED, REPEATABLE READ, and SERIALIZABLE. PostgreSQL treats READ UNCOMMITTED as READ COMMITTED internally.", "source": "transaction_isolation_levels"}
{"id": "pi_003", "domain": "postgresql_internals", "difficulty": "easy", "question": "What is the purpose of Write-Ahead Logging (WAL) in PostgreSQL?", "ground_truth": "WAL ensures data durability and crash recovery by writing all changes to a log file on disk before they are applied to the actual data files. This guarantees that committed transactions are never lost, even in case of sudden failure.", "source": "WAL_internals"}
{"id": "pi_004", "domain": "postgresql_internals", "difficulty": "easy", "question": "What is the default value of the shared_buffers configuration parameter in PostgreSQL?", "ground_truth": "The default value of shared_buffers is 128 MB. It represents the amount of memory allocated for PostgreSQL to use for caching data pages shared among all backends.", "source": "performance_tuning"}
{"id": "pi_005", "domain": "postgresql_internals", "difficulty": "easy", "question": "What does the EXPLAIN command display in PostgreSQL?", "ground_truth": "EXPLAIN displays the query execution plan that PostgreSQL's planner has generated for a given query, showing the operations (scan types, joins, sorts, etc.) and their estimated costs.", "source": "query_planner"}
{"id": "pi_006", "domain": "postgresql_internals", "difficulty": "easy", "question": "What is the main difference between EXPLAIN and EXPLAIN ANALYZE?", "ground_truth": "EXPLAIN shows the estimated plan, while EXPLAIN ANALYZE actually executes the query and displays real runtime statistics (actual rows, execution time) alongside the estimated values.", "source": "query_planner"}
{"id": "pi_007", "domain": "postgresql_internals", "difficulty": "easy", "question": "Name three index types available in PostgreSQL.", "ground_truth": "PostgreSQL supports B-tree, Hash, GiST (Generalized Search Tree), GIN (Generalized Inverted Index), SP-GiST (Space-Partitioned GiST), and BRIN (Block Range Index) index types.", "source": "index_types"}
{"id": "pi_008", "domain": "postgresql_internals", "difficulty": "easy", "question": "What is a partial index in PostgreSQL?", "ground_truth": "A partial index is an index created on a subset of rows in a table, using a WHERE clause to filter which rows are indexed. This reduces index size and improves query performance for specific conditions.", "source": "index_types"}
{"id": "pi_009", "domain": "postgresql_internals", "difficulty": "easy", "question": "What are the three table partitioning strategies supported by PostgreSQL?", "ground_truth": "PostgreSQL supports range partitioning (by value ranges), list partitioning (by specific discrete values), and hash partitioning (by hash of a column value).", "source": "table_partitioning"}
{"id": "pi_010", "domain": "postgresql_internals", "difficulty": "easy", "question": "What is the purpose of VACUUM in PostgreSQL?", "ground_truth": "VACUUM removes dead tuples (rows deleted or updated) from tables, freeing up space and preventing transaction ID wraparound issues. It also updates visibility information and table statistics.", "source": "VACUUM"}
{"id": "pi_011", "domain": "postgresql_internals", "difficulty": "easy", "question": "What is the difference between VACUUM and VACUUM FULL?", "ground_truth": "VACUUM removes dead tuples but does not return space to the operating system; VACUUM FULL rewrites the entire table to a new file and returns unused space to the OS, but requires an exclusive lock and takes longer.", "source": "VACUUM"}
{"id": "pi_012", "domain": "postgresql_internals", "difficulty": "easy", "question": "What is autovacuum in PostgreSQL?", "ground_truth": "Autovacuum is a background daemon that automatically runs VACUUM and ANALYZE on tables based on activity thresholds, preventing dead tuple accumulation and maintaining table statistics without manual intervention.", "source": "autovacuum"}
{"id": "pi_013", "domain": "postgresql_internals", "difficulty": "easy", "question": "What is transaction ID wraparound, and why is it a concern?", "ground_truth": "Transaction ID wraparound occurs when the 32-bit transaction ID counter reaches its maximum and resets to zero. This can make old tuples appear newer than recent ones, causing data corruption unless VACUUM is run regularly to freeze transaction IDs.", "source": "VACUUM"}
{"id": "pi_014", "domain": "postgresql_internals", "difficulty": "easy", "question": "What does a checkpoint do in PostgreSQL's WAL system?", "ground_truth": "A checkpoint writes all dirty pages from shared_buffers to disk and creates a checkpoint record in the WAL. This marks a point in the WAL that recovery can restart from, reducing recovery time and controlling WAL file size.", "source": "WAL_configuration"}
{"id": "pi_015", "domain": "postgresql_internals", "difficulty": "easy", "question": "What is asynchronous commit (async commit) in PostgreSQL?", "ground_truth": "Asynchronous commit allows a transaction to return success to the client before the WAL is guaranteed to be written to disk, trading durability for speed. It is enabled by setting synchronous_commit to off.", "source": "async_commit"}
{"id": "pi_016", "domain": "postgresql_internals", "difficulty": "easy", "question": "What parameter controls the amount of memory available to a single query operation in PostgreSQL?", "ground_truth": "The work_mem parameter controls the maximum amount of memory (in KB) that can be used by a single operation (sort, hash, etc.) before spilling to disk. The default is typically 4 MB.", "source": "performance_tuning"}
{"id": "pi_017", "domain": "postgresql_internals", "difficulty": "easy", "question": "What is the purpose of the effective_cache_size parameter?", "ground_truth": "effective_cache_size tells the query planner the total amount of memory available on the system for caching (including OS cache and shared_buffers). The planner uses this to decide between index scans and sequential scans.", "source": "performance_tuning"}
{"id": "pi_018", "domain": "postgresql_internals", "difficulty": "easy", "question": "What information does the ANALYZE command collect in PostgreSQL?", "ground_truth": "ANALYZE scans tables and collects statistics about the distribution of column values, such as row counts, null percentages, and value frequencies. These statistics are used by the query planner to estimate costs and choose optimal execution plans.", "source": "query_planner"}
{"id": "pi_019", "domain": "postgresql_internals", "difficulty": "easy", "question": "Which index type is best suited for full-text search in PostgreSQL?", "ground_truth": "GIN (Generalized Inverted Index) is best suited for full-text search because it efficiently indexes and searches for multiple values within a single column, making it ideal for text search queries.", "source": "index_types"}
{"id": "pi_020", "domain": "postgresql_internals", "difficulty": "easy", "question": "What is a join strategy in the PostgreSQL query planner?", "ground_truth": "A join strategy is the method used to combine rows from two tables. PostgreSQL supports nested loop joins, hash joins, and merge sort joins, each with different performance characteristics depending on data size and distribution.", "source": "query_planner"}
{"id": "pi_021", "domain": "postgresql_internals", "difficulty": "medium", "question": "Explain the relationship between MVCC tuple visibility and transaction isolation levels. Why does READ UNCOMMITTED not exist in PostgreSQL, and what level does it map to?", "ground_truth": "PostgreSQL implements MVCC using tuple visibility rules based on xmin/xmax transaction IDs. READ UNCOMMITTED is not supported; PostgreSQL maps it to READ COMMITTED, which respects MVCC visibility rules and prevents dirty reads by design. This reflects PostgreSQL's architecture where even the lowest isolation level enforces consistent snapshots.", "source": "MVCC_transaction_isolation"}
{"id": "pi_022", "domain": "postgresql_internals", "difficulty": "medium", "question": "What is the purpose of the xmin and xmax fields in a PostgreSQL tuple header, and how do they interact with the visibility map during VACUUM operations?", "ground_truth": "xmin records the transaction ID that inserted the tuple; xmax records the transaction ID that deleted it. The visibility map (VM) tracks which pages contain only visible tuples, allowing VACUUM to skip full page scans and enabling index-only scans. Dead tuples (with committed xmax) are candidates for cleanup.", "source": "tuple_visibility_xmin_xmax"}
{"id": "pi_023", "domain": "postgresql_internals", "difficulty": "medium", "question": "Describe the trade-offs between synchronous_commit=on and synchronous_commit=local. In what scenarios would you choose local over full synchronous?", "ground_truth": "synchronous_commit=on waits for WAL writes to disk and replica acknowledgment, ensuring maximum durability but with higher latency. synchronous_commit=local only waits for local disk write, reducing latency while still protecting against server crashes. Local is preferred in scenarios prioritizing performance over replication consistency.", "source": "WAL_async_commit_configuration"}
{"id": "pi_024", "domain": "postgresql_internals", "difficulty": "medium", "question": "How does the WAL (Write-Ahead Logging) guarantee crash recovery? What role do checkpoint records play in recovery time objectives?", "ground_truth": "WAL ensures durability by writing changes to disk before applying them to data pages. During recovery, PostgreSQL replays WAL records from the last checkpoint forward. Checkpoints create a consistent point, reducing recovery time by eliminating the need to replay the entire WAL history from the beginning.", "source": "WAL_checkpoint_crash_recovery"}
{"id": "pi_025", "domain": "postgresql_internals", "difficulty": "medium", "question": "Explain how the query planner estimates costs using seq_page_cost and random_page_cost. Why might you lower random_page_cost on SSD storage?", "ground_truth": "The planner uses seq_page_cost (default 1.0) for sequential reads and random_page_cost (default 4.0) for random reads to estimate query cost. On SSDs, random access latency approaches sequential latency, so lowering random_page_cost (e.g., to 1.1) encourages the planner to choose index scans over sequential scans.", "source": "query_planner_cost_estimation"}
{"id": "pi_026", "domain": "postgresql_internals", "difficulty": "medium", "question": "What information does EXPLAIN ANALYZE provide that EXPLAIN does not? How can discrepancies between planned and actual rows indicate query issues?", "ground_truth": "EXPLAIN ANALYZE executes the query and shows actual row counts, execution time per node, and I/O statistics alongside planned estimates. Large discrepancies (planned vs. actual rows) suggest inaccurate statistics, missing indexes, or suboptimal join ordering, indicating the need for ANALYZE or configuration tuning.", "source": "EXPLAIN_ANALYZE_diagnostics"}
{"id": "pi_027", "domain": "postgresql_internals", "difficulty": "medium", "question": "Compare nested loop joins, hash joins, and merge joins in PostgreSQL. Under what conditions would the planner prefer each strategy?", "ground_truth": "Nested loop is efficient for small inner relations or when an index is available. Hash joins are faster for large equi-joins with sufficient work_mem. Merge joins work on pre-sorted data and don't require hashing. Planner chooses based on table sizes, available memory, sort order, and join conditions.", "source": "query_planner_join_strategies"}
{"id": "pi_028", "domain": "postgresql_internals", "difficulty": "medium", "question": "Describe the structure and use case of a B-tree index in PostgreSQL. Why are B-tree indexes preferred for most workloads over other index types?", "ground_truth": "B-tree indexes organize keys in a balanced tree structure supporting equality and range queries efficiently (O(log N) lookup). They support ORDER BY, can handle all comparison operators, and work as both regular and unique indexes. They're preferred because they're general-purpose, require minimal tuning, and handle both point and range queries well.", "source": "index_types_btree"}
{"id": "pi_029", "domain": "postgresql_internals", "difficulty": "medium", "question": "What is a GIN (Generalized Inverted Index) and for what data types is it most beneficial? Explain the trade-off between index size and query performance.", "ground_truth": "GIN indexes are inverted indexes that map values to tuples containing them, ideal for arrays and full-text search. They provide fast queries on multi-valued columns but have slower inserts and larger index sizes due to per-value-per-tuple mapping. Use them when query speed on complex columns outweighs write performance.", "source": "index_types_GIN"}
{"id": "pi_030", "domain": "postgresql_internals", "difficulty": "medium", "question": "Explain partial indexes and expression indexes. Provide a practical example where each would improve performance over a full-table index.", "ground_truth": "Partial indexes index only rows matching a WHERE clause (e.g., WHERE status='active'), reducing index size and maintenance overhead. Expression indexes store computed values (e.g., LOWER(email)) for faster lookups on derived data. Use partial for filtered queries and expression indexes for function-based predicates to avoid repeated computation.", "source": "index_types_partial_expression"}
{"id": "pi_031", "domain": "postgresql_internals", "difficulty": "medium", "question": "How does range partitioning differ from list partitioning in PostgreSQL? Describe a scenario where range partitioning is more appropriate.", "ground_truth": "Range partitioning divides data by value ranges (e.g., date ranges), ideal for time-series data with natural ordering. List partitioning maps discrete values to partitions (e.g., by region). Range partitioning is better for time-series because it enables efficient pruning by date, rolling partition retention, and natural partition sizing.", "source": "table_partitioning_range_list"}
{"id": "pi_032", "domain": "postgresql_internals", "difficulty": "medium", "question": "What is constraint exclusion, and how does it interact with partitioning? Why is it essential for partition pruning during query planning?", "ground_truth": "Constraint exclusion is an optimization that uses table constraints (e.g., CHECK conditions) to eliminate partitions that cannot contain matching rows at plan time. It's enabled by constraint_exclusion=partition and is essential for partition pruning\u2014without it, the planner scans all partitions regardless of the WHERE clause.", "source": "table_partitioning_constraint_exclusion"}
{"id": "pi_033", "domain": "postgresql_internals", "difficulty": "medium", "question": "Explain the purpose of VACUUM FULL and its performance implications. When should it be used versus regular VACUUM?", "ground_truth": "VACUUM FULL rewrites tables to disk, reclaiming all dead space and rebuilding indexes, but requires an exclusive lock blocking all access. Regular VACUUM marks dead tuples as reusable without blocking. Use VACUUM FULL only for severely bloated tables during maintenance windows; autovacuum handles regular maintenance.", "source": "VACUUM_FULL_bloat_cleanup"}
{"id": "pi_034", "domain": "postgresql_internals", "difficulty": "medium", "question": "What is transaction ID wraparound, and how does autovacuum prevent it? Why is it a critical maintenance concern?", "ground_truth": "PostgreSQL uses 32-bit transaction IDs; after ~2 billion transactions, the counter wraps, causing tuple visibility rules to fail and data corruption. Autovacuum prevents wraparound by enforcing VACUUM when xmin_age approaches the wraparound threshold (autovacuum_freeze_max_age, default ~200M). Wraparound prevention is critical because undetected wraparound causes database corruption.", "source": "VACUUM_autovacuum_txid_wraparound"}
{"id": "pi_035", "domain": "postgresql_internals", "difficulty": "medium", "question": "Describe how autovacuum's adaptive behavior works. What parameters control its aggressiveness, and how would you tune it for a high-write OLTP workload?", "ground_truth": "Autovacuum triggers when dead tuples exceed a threshold based on autovacuum_vacuum_threshold + (table_rows * autovacuum_vacuum_scale_factor). For high-write OLTP, reduce autovacuum_vacuum_scale_factor and autovacuum_naptime to vacuum more frequently, and increase autovacuum_max_workers to parallelize vacuuming across tables.", "source": "autovacuum_tuning_parameters"}
{"id": "pi_036", "domain": "postgresql_internals", "difficulty": "medium", "question": "How does shared_buffers interact with the OS page cache? What is the risk of setting shared_buffers too high?", "ground_truth": "shared_buffers is PostgreSQL's in-process cache; data also caches in the OS page cache. Setting it too high risks double-buffering (same data in both caches, wasting memory) and reduced effectiveness of OS-level cache management. Recommended is 25% of system RAM; beyond that, diminishing returns occur as the OS cache becomes less effective.", "source": "performance_tuning_shared_buffers"}
{"id": "pi_037", "domain": "postgresql_internals", "difficulty": "medium", "question": "Explain the purpose of work_mem and how it affects query performance and memory usage. What happens when a query exceeds work_mem during sorting or hashing?", "ground_truth": "work_mem limits memory per operation (sort, hash aggregate, hash join); it's per operation, not per query, so complex queries can use multiples. When work_mem is exceeded, PostgreSQL spills to disk (slower but prevents OOM). Setting work_mem too high risks system OOM; too low causes disk spillage. Tune based on query complexity and system RAM.", "source": "performance_tuning_work_mem"}
{"id": "pi_038", "domain": "postgresql_internals", "difficulty": "medium", "question": "What role does effective_cache_size play in query planning? How should it be set relative to actual system memory?", "ground_truth": "effective_cache_size estimates total available cache (shared_buffers + OS cache) to guide the planner's cost calculations. It doesn't allocate memory but influences join strategy and index selection. Set it to shared_buffers + available OS cache (typically 50-75% of total RAM), giving the planner realistic information for choosing efficient plans.", "source": "performance_tuning_effective_cache_size"}
{"id": "pi_039", "domain": "postgresql_internals", "difficulty": "medium", "question": "How does the ANALYZE statement update table statistics, and why is accurate statistics critical for query planning? What is the default auto-analysis behavior?", "ground_truth": "ANALYZE scans tables to compute column value distributions, cardinality, and NULL counts, storing them in pg_statistics. Accurate statistics allow the planner to estimate join selectivity and cost correctly. By default, autovacuum triggers ANALYZE after inserts/updates exceed a threshold, but manual ANALYZE may be needed after bulk loads.", "source": "statistics_collection_ANALYZE"}
{"id": "pi_040", "domain": "postgresql_internals", "difficulty": "medium", "question": "Describe how repetitive plan caching in PostgreSQL works for prepared statements. How does it interact with statistics and when might stale plans cause performance degradation?", "ground_truth": "Prepared statements cache parsed and planned queries; the planner generates a generic plan after 5 executions with different parameters to avoid replanning overhead. Stale plans occur when table statistics change significantly (new data distribution) after planning but before execution, causing suboptimal join orders or index choices. Re-planning or ANALYZE may be needed after major data changes.", "source": "query_planner_prepared_statements"}
{"id": "pi_041", "domain": "postgresql_internals", "difficulty": "hard", "question": "Explain the relationship between transaction ID (xid) wraparound and VACUUM's role in preventing database corruption. What specific PostgreSQL setting controls the threshold for forced autovacuum?", "ground_truth": "PostgreSQL uses 32-bit transaction IDs that wrap around after ~4 billion transactions. When the difference between the current xid and the oldest unfrozen xid in any table approaches autovacuum_freeze_max_age (default 50 million), autovacuum is forced to run and freeze tuples to prevent xid wraparound. Without this, the database becomes read-only to prevent corruption. The autovacuum_freeze_max_age parameter controls this threshold.", "source": "VACUUM_xid_wraparound"}
{"id": "pi_042", "domain": "postgresql_internals", "difficulty": "hard", "question": "In PostgreSQL MVCC, what is the difference between t_infomask hint bits and the clog (commit log), and why does PostgreSQL maintain both? Under what conditions might a hint bit be cleared?", "ground_truth": "t_infomask hint bits cache visibility information on the tuple itself (HEAP_XMIN_COMMITTED, HEAP_XMAX_COMMITTED) for fast lookup, while clog is the authoritative record of transaction commit status. Hint bits reduce clog lookups but clog remains the source of truth. Hint bits are cleared when a page is pruned due to xmin/xmax changes or when anti-wraparound vacuums are performed to ensure correct visibility checks.", "source": "MVCC_visibility_clog"}
{"id": "pi_043", "domain": "postgresql_internals", "difficulty": "hard", "question": "When using asynchronous commit (synchronous_commit = off), what is the risk of data loss, and how does the WAL configuration parameter wal_sync_method influence this risk?", "ground_truth": "With async commit, a transaction returns to the client before WAL is flushed to disk, risking loss of recently committed transactions during a server crash. wal_sync_method (fsync, fdatasync, open_sync, open_datasync) determines how WAL is persisted; unsafe methods like open_sync may not guarantee durability even for sync commits. Async commit trades durability for performance, accepting potential data loss within one checkpoint interval.", "source": "WAL_async_commit"}
{"id": "pi_044", "domain": "postgresql_internals", "difficulty": "hard", "question": "Describe how PostgreSQL's query planner uses the Statistics Collector and how underestimated row counts in EXPLAIN ANALYZE output can cascade into poor join strategy choices. What statistic is most critical for join planning?", "ground_truth": "The Statistics Collector (stats_temp_directory) maintains pg_stat_user_tables and histogram statistics. Underestimated row counts cause the planner to choose Nested Loop joins when Hash Joins are more efficient, as cost is calculated as rows \u00d7 per-row cost. The most critical statistic is the n_distinct estimate for WHERE clause columns and join keys, as errors here directly propagate to selectivity estimates affecting join cardinality predictions.", "source": "planner_statistics"}
{"id": "pi_045", "domain": "postgresql_internals", "difficulty": "hard", "question": "Explain how partial indexes interact with query planning and the specific conditions under which the planner will use a partial index versus a full table scan, even when the partial index covers the query predicate.", "ground_truth": "A partial index is only chosen by the planner if the query's WHERE clause is provably a superset of (or equal to) the index's WHERE clause. Even if the partial index covers all required columns, the planner must determine the predicate is guaranteed to match the index filter; weak constraint inference may cause the planner to reject the index. The predicate_proof() function performs this check, and if the planner cannot prove equivalence, it falls back to sequential scan.", "source": "index_partial_planning"}
{"id": "pi_046", "domain": "postgresql_internals", "difficulty": "hard", "question": "In the context of GIN (Generalized Inverted Index) indexes, explain the role of the posting list and how pending_list_limit affects performance. Why might high insertion rates cause GIN index bloat despite aggressive vacuuming?", "ground_truth": "GIN indexes use posting lists to store multiple TIDs for a single key; the pending_list_limit (default 4MB) threshold determines when pending entries are flushed to main index pages. High insertion rates can cause bloat because pending lists bypass the main index, and if insertions exceed flush speed, multiple pending pages accumulate. Aggressive vacuuming of the table alone doesn't reclaim GIN index space; gin_pending_list_limit must be tuned or manual REINDEX required.", "source": "GIN_index_internals"}
{"id": "pi_047", "domain": "postgresql_internals", "difficulty": "hard", "question": "Discuss the performance implications of choosing range versus list partitioning for a large time-series table. What query planner optimization specifically makes range partitioning superior for time-based queries, and when might constraint exclusion fail?", "ground_truth": "Range partitioning enables constraint exclusion, where the planner prunes partitions based on implicit CHECK constraints derived from partition bounds. For time-series data with time-based queries, range partitions allow scanning only relevant date ranges, reducing I/O significantly. Constraint exclusion fails if: (1) the query uses expressions (e.g., WHERE date_col + interval > X), (2) the planner cannot infer bounds from subqueries, or (3) constraint_exclusion is disabled. List partitioning offers weaker pruning opportunities.", "source": "partitioning_constraint_exclusion"}
{"id": "pi_048", "domain": "postgresql_internals", "difficulty": "hard", "question": "Explain the interaction between VACUUM FULL, table bloat, and the table's pg_class.relfrozenxid. What happens if VACUUM FULL is blocked by long-running transactions, and what are the security implications of the temporary unlogged table created during VACUUM FULL?", "ground_truth": "VACUUM FULL rewrites the entire table to reclaim dead space and updates relfrozenxid by freezing tuples; it creates a temporary unlogged table which is unsafe if the server crashes before replication to the main table completes. If long-running transactions exist with xmin older than the frozen xid, VACUUM FULL cannot proceed, risking xid wraparound. The temporary table is world-readable by default, potentially exposing sensitive data to unprivileged users.", "source": "VACUUM_FULL_internals"}
{"id": "pi_049", "domain": "postgresql_internals", "difficulty": "hard", "question": "In an ACID compliance context, explain how PostgreSQL's Serializable Isolation Level uses Serialization Conflict Detection (SCD) and when a transaction may be aborted with a serialization_failure error despite no lock conflicts. What is the role of SIREAD locks?", "ground_truth": "Serializable isolation uses Serialization Conflict Detection (predicate locking) rather than two-phase locking. SIREAD locks (Serializable Read) track read dependencies on rows; a transaction is aborted if a committed transaction's writes conflict with the SIREAD set, even with no row locks held. This prevents phantom reads and write skew anomalies. Conflicts are detected post-commit, causing aborts without visible lock contention, and transactions must be retried by the application.", "source": "isolation_serializable_scd"}
{"id": "pi_050", "domain": "postgresql_internals", "difficulty": "hard", "question": "Describe how shared_buffers, work_mem, and effective_cache_size interact to influence the query planner's cost model. What is the risk of setting shared_buffers too high on a system with limited RAM, and how does this affect both planner decisions and runtime performance?", "ground_truth": "shared_buffers caches pages in PostgreSQL memory; work_mem limits per-operation memory (sorts, hash tables); effective_cache_size hints at OS cache availability. The planner uses effective_cache_size to estimate cost of sequential vs. index scans: higher values favor index scans, lower values favor seqs scans. Setting shared_buffers >25% RAM causes OS page cache competition and increased context switching, hurting both planner accuracy (inflated effective_cache_size assumption) and actual query performance due to memory contention and swapping.", "source": "performance_tuning_buffers"}
