[
  {
    "id": "ae_001",
    "domain": "autogen_expert",
    "difficulty": "easy",
    "question": "What is the primary purpose of Microsoft AutoGen?",
    "ground_truth": "Microsoft AutoGen is a multi-agent AI framework designed for building conversational and event-driven agent systems that can collaborate to complete complex tasks.",
    "source": "AutoGen Overview"
  },
  {
    "id": "ae_002",
    "domain": "autogen_expert",
    "difficulty": "easy",
    "question": "What are the two main API approaches provided by AutoGen?",
    "ground_truth": "AutoGen provides the AgentChat API (high-level with preset behaviors) and the Core API (event-driven with message passing).",
    "source": "AgentChat and Core API"
  },
  {
    "id": "ae_003",
    "domain": "autogen_expert",
    "difficulty": "easy",
    "question": "What is ConversableAgent in AutoGen?",
    "ground_truth": "ConversableAgent is a base agent class in AutoGen that implements the core messaging and conversation logic for building conversational agents.",
    "source": "Agents"
  },
  {
    "id": "ae_004",
    "domain": "autogen_expert",
    "difficulty": "easy",
    "question": "What is the primary role of AssistantAgent?",
    "ground_truth": "AssistantAgent is an agent type in AutoGen that uses an LLM to generate intelligent responses and can perform tasks based on user requests and tool usage.",
    "source": "Agents"
  },
  {
    "id": "ae_005",
    "domain": "autogen_expert",
    "difficulty": "easy",
    "question": "What is the purpose of UserProxyAgent?",
    "ground_truth": "UserProxyAgent acts as a proxy for user interactions, allowing human input and oversight in agent conversations while optionally executing code or providing feedback.",
    "source": "Agents"
  },
  {
    "id": "ae_006",
    "domain": "autogen_expert",
    "difficulty": "easy",
    "question": "What is GroupChat used for in AutoGen?",
    "ground_truth": "GroupChat enables multiple agents to participate in a conversation together, with mechanisms for speaker selection and the ability to resume conversations.",
    "source": "GroupChat"
  },
  {
    "id": "ae_007",
    "domain": "autogen_expert",
    "difficulty": "easy",
    "question": "How does SelectorGroupChat differ from standard GroupChat?",
    "ground_truth": "SelectorGroupChat uses an LLM-based speaker selection mechanism to intelligently choose which agent should speak next, rather than using a round-robin or predefined order.",
    "source": "Teams"
  },
  {
    "id": "ae_008",
    "domain": "autogen_expert",
    "difficulty": "easy",
    "question": "What are the two main code executor options available in AutoGen?",
    "ground_truth": "AutoGen provides Docker-based code executors for isolated execution and local code executors for direct execution on the host machine.",
    "source": "Code Executors"
  },
  {
    "id": "ae_009",
    "domain": "autogen_expert",
    "difficulty": "easy",
    "question": "What is MagenticOne in the AutoGen ecosystem?",
    "ground_truth": "MagenticOne is a multi-agent system built on AutoGen that coordinates multiple specialized agents to solve complex tasks collaboratively.",
    "source": "MagenticOne"
  },
  {
    "id": "ae_010",
    "domain": "autogen_expert",
    "difficulty": "easy",
    "question": "What does the Extensions API in AutoGen enable?",
    "ground_truth": "The Extensions API allows customization of LLM clients and code execution environments, enabling integration of custom language models and execution strategies.",
    "source": "Extensions API"
  },
  {
    "id": "ae_011",
    "domain": "autogen_expert",
    "difficulty": "easy",
    "question": "What is AutoGen Studio?",
    "ground_truth": "AutoGen Studio is a no-code user interface for building and configuring AutoGen agent systems without requiring programming knowledge.",
    "source": "AutoGen Studio"
  },
  {
    "id": "ae_012",
    "domain": "autogen_expert",
    "difficulty": "easy",
    "question": "What major change was introduced in AutoGen v0.4?",
    "ground_truth": "AutoGen v0.4 redesigned the framework with async messaging, improved event handling, and added cross-language support for building agents.",
    "source": "v0.4 Redesign"
  },
  {
    "id": "ae_013",
    "domain": "autogen_expert",
    "difficulty": "easy",
    "question": "What is the relationship between AutoGen and the Microsoft Agent Framework?",
    "ground_truth": "AutoGen provides a migration path to the Microsoft Agent Framework, allowing users to transition their agent systems to the broader enterprise framework.",
    "source": "Migration Path"
  },
  {
    "id": "ae_014",
    "domain": "autogen_expert",
    "difficulty": "easy",
    "question": "How can custom functions be integrated into AutoGen agents?",
    "ground_truth": "Custom functions can be registered as tools on agents, enabling agents to call user-defined functions as part of their task execution.",
    "source": "Tools and Custom Functions"
  },
  {
    "id": "ae_015",
    "domain": "autogen_expert",
    "difficulty": "easy",
    "question": "What is state management in AutoGen used for?",
    "ground_truth": "State management in AutoGen maintains agent conversation history, context, and configuration state to enable resumable and persistent multi-agent interactions.",
    "source": "State Management"
  },
  {
    "id": "ae_016",
    "domain": "autogen_expert",
    "difficulty": "easy",
    "question": "What is the primary advantage of using the AgentChat API over the Core API?",
    "ground_truth": "The AgentChat API provides high-level, preset agent behaviors that simplify development, while the Core API offers more low-level control through event-driven message passing.",
    "source": "AgentChat API"
  },
  {
    "id": "ae_017",
    "domain": "autogen_expert",
    "difficulty": "easy",
    "question": "What does speaker selection in GroupChat determine?",
    "ground_truth": "Speaker selection determines which agent in a group conversation speaks next, controlling the flow and order of contributions from multiple agents.",
    "source": "GroupChat"
  },
  {
    "id": "ae_018",
    "domain": "autogen_expert",
    "difficulty": "easy",
    "question": "What is the benefit of using Docker-based code executors in AutoGen?",
    "ground_truth": "Docker-based code executors provide isolated execution environments, improving security and preventing malicious or faulty code from affecting the host system.",
    "source": "Code Executors"
  },
  {
    "id": "ae_019",
    "domain": "autogen_expert",
    "difficulty": "easy",
    "question": "What is a Team in AutoGen?",
    "ground_truth": "A Team in AutoGen is a collection of agents that work together, typically managed by a chat structure or orchestrator to accomplish collaborative goals.",
    "source": "Teams"
  },
  {
    "id": "ae_020",
    "domain": "autogen_expert",
    "difficulty": "easy",
    "question": "What programming model does AutoGen's v0.4 emphasize?",
    "ground_truth": "AutoGen v0.4 emphasizes async messaging and event-driven programming, enabling more responsive and scalable multi-agent systems.",
    "source": "v0.4 Redesign"
  },
  {
    "id": "ae_021",
    "domain": "autogen_expert",
    "difficulty": "medium",
    "question": "What is the primary architectural difference between the AgentChat API and the Core API in AutoGen, and when would you choose one over the other?",
    "ground_truth": "The AgentChat API provides high-level, preset agent behaviors with simplified interfaces, while the Core API is event-driven and message-passing based for fine-grained control. Use AgentChat for rapid development with standard agent patterns; use Core API when you need custom event handling and complex orchestration.",
    "source": "AgentChat_vs_CoreAPI"
  },
  {
    "id": "ae_022",
    "domain": "autogen_expert",
    "difficulty": "medium",
    "question": "Explain how speaker selection works in GroupChat and what problem it solves in multi-agent conversations.",
    "ground_truth": "Speaker selection determines which agent responds next in a group conversation based on predefined rules or custom logic. It solves the problem of preventing all agents from responding simultaneously and ensures efficient, turn-based dialogue flow in multi-agent systems.",
    "source": "GroupChat_speaker_selection"
  },
  {
    "id": "ae_023",
    "domain": "autogen_expert",
    "difficulty": "medium",
    "question": "What are the key differences between ConversableAgent, AssistantAgent, and UserProxyAgent in terms of their capabilities and intended use cases?",
    "ground_truth": "ConversableAgent is a base agent for custom implementations; AssistantAgent represents LLM-powered agents with tool use capabilities; UserProxyAgent simulates human input or code execution oversight. Use AssistantAgent for autonomous LLM reasoning, UserProxyAgent for human-in-the-loop scenarios.",
    "source": "Agent_types"
  },
  {
    "id": "ae_024",
    "domain": "autogen_expert",
    "difficulty": "medium",
    "question": "How does the resume functionality in GroupChat contribute to handling interruptions and context preservation in multi-agent conversations?",
    "ground_truth": "Resume allows a paused GroupChat to restart from its previous state without losing conversation history or agent internal state. This enables handling of interruptions, dynamic agent addition/removal, and recovery from failures while maintaining conversation context.",
    "source": "GroupChat_resume"
  },
  {
    "id": "ae_025",
    "domain": "autogen_expert",
    "difficulty": "medium",
    "question": "What is SelectorGroupChat and how does it improve upon standard GroupChat for handling complex multi-agent orchestration?",
    "ground_truth": "SelectorGroupChat uses a dedicated selector agent to intelligently choose which agent should speak next based on the conversation state, replacing static speaker selection rules. This enables more sophisticated decision-making and dynamic routing in complex multi-agent systems.",
    "source": "SelectorGroupChat"
  },
  {
    "id": "ae_026",
    "domain": "autogen_expert",
    "difficulty": "medium",
    "question": "Describe the trade-offs between using Docker-based code execution and local code execution in AutoGen, including security and performance implications.",
    "ground_truth": "Docker execution provides better isolation and security by sandboxing code in containers, preventing system compromise, but adds overhead and requires Docker setup. Local execution is faster and simpler but poses security risks if agent-generated code is untrusted; use Docker for untrusted code, local for trusted environments.",
    "source": "Code_executors"
  },
  {
    "id": "ae_027",
    "domain": "autogen_expert",
    "difficulty": "medium",
    "question": "What role does the Extensions API play in AutoGen's design, and provide an example of how it enables customization.",
    "ground_truth": "The Extensions API allows pluggable customization of LLM clients and code execution backends without modifying core AutoGen code. Examples include implementing custom LLM clients for proprietary models or alternative code execution runtimes like Kubernetes.",
    "source": "Extensions_API"
  },
  {
    "id": "ae_028",
    "domain": "autogen_expert",
    "difficulty": "medium",
    "question": "How does MagenticOne differ from standard AutoGen agent configurations, and what types of problems is it designed to solve?",
    "ground_truth": "MagenticOne is a pre-configured multi-agent system with specialized agents for web search, code execution, and task planning. It is designed to solve complex, open-ended research and development tasks that require autonomous planning, web interaction, and code execution without explicit human direction.",
    "source": "MagenticOne"
  },
  {
    "id": "ae_029",
    "domain": "autogen_expert",
    "difficulty": "medium",
    "question": "Explain the relationship between tools and custom functions in AutoGen agents, and how they are registered and invoked.",
    "ground_truth": "Tools are structured definitions of functions that agents can call, while custom functions are the actual implementations. Tools are registered via the agent's tool registry with proper schemas; agents invoke them by parsing LLM outputs or explicit function calls, with the framework handling parameter passing and execution.",
    "source": "Tools_custom_functions"
  },
  {
    "id": "ae_030",
    "domain": "autogen_expert",
    "difficulty": "medium",
    "question": "What state management challenges arise in long-running multi-agent systems, and what strategies does AutoGen provide to address them?",
    "ground_truth": "Challenges include agent memory corruption, inconsistent conversation state, and loss of context across resumptions. AutoGen addresses these through explicit state serialization, the resume capability in teams, and conversation history preservation in agent objects.",
    "source": "State_management"
  },
  {
    "id": "ae_031",
    "domain": "autogen_expert",
    "difficulty": "medium",
    "question": "How does AutoGen Studio enable non-technical users to build agent systems, and what are its limitations compared to programmatic approaches?",
    "ground_truth": "AutoGen Studio provides a no-code UI for visual agent and workflow design, configuration management, and deployment without coding. Limitations include reduced customization depth, inability to implement complex custom logic, and potential performance overhead compared to hand-optimized code.",
    "source": "AutoGen_Studio"
  },
  {
    "id": "ae_032",
    "domain": "autogen_expert",
    "difficulty": "medium",
    "question": "Explain the significance of the v0.4 redesign's focus on async messaging and its impact on agent concurrency and scalability.",
    "ground_truth": "v0.4 replaced synchronous messaging with async messaging to enable concurrent agent execution and non-blocking I/O. This improves scalability by allowing agents to execute in parallel and reduces latency in systems with many agents or slow external service calls.",
    "source": "v0.4_redesign"
  },
  {
    "id": "ae_033",
    "domain": "autogen_expert",
    "difficulty": "medium",
    "question": "What is the migration path from AutoGen to Microsoft Agent Framework, and what should developers consider when planning this transition?",
    "ground_truth": "The migration path involves gradual adoption of Agent Framework APIs while maintaining backward compatibility with AutoGen code. Developers should assess which AutoGen patterns map to Agent Framework equivalents, plan for API differences, and test migration incrementally to avoid service disruptions.",
    "source": "Migration_to_Agent_Framework"
  },
  {
    "id": "ae_034",
    "domain": "autogen_expert",
    "difficulty": "medium",
    "question": "How does the termination condition system in AutoGen teams prevent infinite loops, and what are the different termination strategies available?",
    "ground_truth": "Termination conditions evaluate conversation state after each turn to decide if the team should stop. Strategies include max turn limits, detecting stop keywords or exit conditions, checking for convergence, or task completion signals. Multiple conditions can be combined with AND/OR logic.",
    "source": "Termination"
  },
  {
    "id": "ae_035",
    "domain": "autogen_expert",
    "difficulty": "medium",
    "question": "Describe how teams in AutoGen differ from standalone agents, and explain when you would use a team instead of a single agent.",
    "ground_truth": "Teams are orchestrated collections of agents working together on shared tasks, while standalone agents work in isolation. Use teams for tasks requiring diverse expertise, parallel processing, debate/voting mechanisms, or separation of concerns; use single agents for simple, focused tasks.",
    "source": "Teams"
  },
  {
    "id": "ae_036",
    "domain": "autogen_expert",
    "difficulty": "medium",
    "question": "How does AutoGen's model configuration system handle multiple LLM providers, and what happens when a primary model fails or reaches rate limits?",
    "ground_truth": "AutoGen supports model configuration with fallback lists, allowing agents to try alternative models or providers in sequence. When a primary model fails or hits rate limits, the framework automatically attempts the next configured model, enabling graceful degradation and improved reliability.",
    "source": "Models"
  },
  {
    "id": "ae_037",
    "domain": "autogen_expert",
    "difficulty": "medium",
    "question": "What are the key considerations when designing a research task for a multi-agent group chat, and how should agent roles be structured?",
    "ground_truth": "Key considerations include clearly defining the research objective, assigning complementary roles (e.g., researcher, analyst, critic), enabling knowledge sharing via conversation history, and setting appropriate termination conditions. Roles should balance specialization with the ability to contribute meaningfully to discussion.",
    "source": "Research_with_MultiAgent_GroupChat"
  },
  {
    "id": "ae_038",
    "domain": "autogen_expert",
    "difficulty": "medium",
    "question": "Explain how cross-language support in v0.4 enables integration with non-Python systems, and what communication mechanisms enable this.",
    "ground_truth": "v0.4's cross-language support uses standardized message protocols and APIs (e.g., gRPC, REST) that allow agents written in different languages to communicate. This enables Python agents to work alongside Java, C#, or other language implementations in polyglot systems.",
    "source": "v0.4_cross_language"
  },
  {
    "id": "ae_039",
    "domain": "autogen_expert",
    "difficulty": "medium",
    "question": "What is the relationship between agent personas and conversation behavior, and how should persona prompts be crafted for effective multi-agent dynamics?",
    "ground_truth": "Agent personas, defined in system prompts, shape how agents interpret tasks and interact with peers. Effective personas are distinct enough to provide unique perspectives, aligned with agent capabilities, and explicit about role responsibilities to enable productive collaboration and reduce redundancy.",
    "source": "Agents"
  },
  {
    "id": "ae_040",
    "domain": "autogen_expert",
    "difficulty": "medium",
    "question": "How does the quickstart guide demonstrate the progression from simple single-agent setups to complex multi-agent teams, and what concepts are foundational?",
    "ground_truth": "The quickstart progresses from agent creation and basic conversation, to adding tools and code execution, to grouping agents in teams with speaker selection. Foundational concepts include agent initialization, message passing, tool registration, team orchestration, and termination handling.",
    "source": "Quickstart"
  },
  {
    "id": "ae_041",
    "domain": "autogen_expert",
    "difficulty": "hard",
    "question": "In AutoGen's v0.4 redesign, how does the shift from synchronous to asynchronous messaging architecture impact agent scalability and what are the implications for handling high-frequency inter-agent communication patterns?",
    "ground_truth": "The async messaging architecture in v0.4 enables non-blocking agent interactions and better resource utilization, allowing agents to await responses without blocking threads. This improves scalability for systems with many concurrent agents and high-frequency message passing by leveraging async/await patterns and event loops instead of blocking I/O.",
    "source": "v0.4_redesign_async_messaging"
  },
  {
    "id": "ae_042",
    "domain": "autogen_expert",
    "difficulty": "hard",
    "question": "When implementing a SelectorGroupChat with custom speaker selection logic, what are the critical performance and correctness considerations when the selector function has O(n) complexity and agents frequently produce long context windows?",
    "ground_truth": "Custom selector functions in SelectorGroupChat should minimize computational overhead as they execute after every agent message; O(n) complexity becomes problematic with many agents or frequent selections. Long context windows compound this by increasing token counting and LLM-based selection costs; consider memoization, context summarization, or heuristic-based selection to mitigate performance degradation.",
    "source": "SelectorGroupChat_speaker_selection"
  },
  {
    "id": "ae_043",
    "domain": "autogen_expert",
    "difficulty": "hard",
    "question": "Explain the architectural differences between ConversableAgent, AssistantAgent, and UserProxyAgent and when you would choose one over another in a complex multi-agent system where some agents should handle tool execution while others should not.",
    "ground_truth": "ConversableAgent is the base class with customizable message handling; AssistantAgent is specialized for LLM-driven agents with tool use capabilities; UserProxyAgent simulates human input and typically executes code without making autonomous LLM calls. Choose AssistantAgent for autonomous tool-using agents, UserProxyAgent for human interaction or code execution orchestration, and ConversableAgent when you need custom message processing logic.",
    "source": "ConversableAgent_AssistantAgent_UserProxyAgent"
  },
  {
    "id": "ae_044",
    "domain": "autogen_expert",
    "difficulty": "hard",
    "question": "In the Core API's event-driven architecture, how does message passing between agents differ from the AgentChat API's preset behaviors, and what are the security implications of implementing custom message handlers?",
    "ground_truth": "The Core API uses explicit event-driven message passing with fine-grained control over message routing and handling, while AgentChat API abstracts this with preset conversation patterns. Custom message handlers in Core API can bypass security checks or modify messages unexpectedly; developers must validate message content, enforce access control, and be cautious with agent state mutations to prevent injection attacks or unintended side effects.",
    "source": "Core_API_event_driven_message_passing"
  },
  {
    "id": "ae_045",
    "domain": "autogen_expert",
    "difficulty": "hard",
    "question": "When using Docker-based code executors in AutoGen, what are the memory isolation, timeout handling, and resource cleanup considerations that differ from local executors, and how should they inform your agent design?",
    "ground_truth": "Docker executors provide process isolation and prevent resource exhaustion on the host, but introduce overhead and timeout complexity; containers must be properly cleaned up to avoid resource leaks. Local executors are faster but less safe. Agent design should account for Docker startup latency, set appropriate timeouts per task complexity, implement health checks, and use container resource limits (memory, CPU) to prevent runaway agents from impacting system stability.",
    "source": "code_executors_Docker_local"
  },
  {
    "id": "ae_046",
    "domain": "autogen_expert",
    "difficulty": "hard",
    "question": "In a GroupChat with resume functionality, describe the state management challenges when agents are paused mid-conversation and resumed later, particularly regarding message history truncation, context loss, and LLM context window limits.",
    "ground_truth": "Resume functionality must preserve agent state and message history accurately; challenges include: context window limits requiring message summarization/truncation (losing nuance), maintaining agent-specific memory across pauses, ensuring conversation coherence when resuming with stale agent states, and handling model changes between pause/resume cycles. Implement explicit state serialization, summary caching, and version tracking of agent configurations to manage these issues.",
    "source": "GroupChat_resume_state_management"
  },
  {
    "id": "ae_047",
    "domain": "autogen_expert",
    "difficulty": "hard",
    "question": "How does MagenticOne's architecture leverage multiple specialized agents to overcome individual LLM limitations in complex reasoning tasks, and what are the failure modes when agent specialization is poorly designed?",
    "ground_truth": "MagenticOne uses a multi-agent system where specialized agents handle specific sub-tasks (e.g., web search, code execution, reasoning) coordinated by an orchestrator; this overcomes single-model limitations through task decomposition. Failure modes include: poor task boundaries causing redundant work, agents lacking sufficient context, unhandled dependencies between tasks, and cascading failures when one agent produces invalid output that downstream agents cannot process.",
    "source": "MagenticOne_multi_agent_system"
  },
  {
    "id": "ae_048",
    "domain": "autogen_expert",
    "difficulty": "hard",
    "question": "When implementing custom tools and functions in AutoGen, what validation, error handling, and state management patterns are essential to prevent agent hallucination about tool capabilities and avoid infinite retry loops?",
    "ground_truth": "Custom tools must include explicit return schemas with clear success/failure indicators, parameter validation before execution, and informative error messages that agents can parse. Implement tool versioning, capability declarations in tool definitions, max-retry limits, and circuit breaker patterns to prevent infinite loops. Agent prompts should be explicit about tool limitations and expected failure modes to reduce hallucination about tool behavior.",
    "source": "tools_custom_functions_validation"
  },
  {
    "id": "ae_049",
    "domain": "autogen_expert",
    "difficulty": "hard",
    "question": "Describe the architectural challenges of implementing cross-language support in AutoGen v0.4's redesign and how the Extensions API addresses LLM client and code execution interoperability.",
    "ground_truth": "Cross-language support requires language-agnostic message formats, protocol standardization, and type serialization; v0.4 addresses this through the Extensions API, which decouples LLM clients and code executors from core agent logic using pluggable interfaces. This enables Python, JavaScript, Java, and other languages to implement agents while maintaining interoperability through standard message schemas and REST/gRPC communication boundaries.",
    "source": "Extensions_API_cross_language_LLM_clients"
  },
  {
    "id": "ae_050",
    "domain": "autogen_expert",
    "difficulty": "hard",
    "question": "Given AutoGen's transition to Microsoft Agent Framework, what are the critical architectural incompatibilities between AutoGen v0.3 agents and the new framework, and what does a realistic migration strategy require?",
    "ground_truth": "v0.3 relied on synchronous message passing and tightly coupled agent definitions; the new framework uses async/await patterns and decoupled agent protocols. Migration requires rewriting agent implementations to async patterns, updating message handlers to new API signatures, potentially reimplementing custom agents using the new ConversableAgent base, and updating Teams definitions. Some edge cases with complex state management or synchronous-dependent logic may require significant refactoring.",
    "source": "migration_path_Microsoft_Agent_Framework"
  }
]
