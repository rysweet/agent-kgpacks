"""Evaluation data models for knowledge pack assessment.

This module provides dataclasses for representing evaluation questions,
answers, metrics, and results used in the three-baseline comparison system.
"""

from dataclasses import dataclass


@dataclass
class Question:
    """A question used for evaluating knowledge pack quality.

    Attributes:
        id: Unique identifier for the question
        question: The question text to ask the model
        ground_truth: Expected correct answer for comparison
        domain: Domain/topic of the question (e.g., "physics", "history")
        difficulty: Difficulty level ("easy", "medium", "hard")
    """

    id: str
    question: str
    ground_truth: str
    domain: str
    difficulty: str  # "easy", "medium", "hard"


@dataclass
class Answer:
    """An answer generated by one of the evaluation baselines.

    Attributes:
        question_id: ID of the question this answers
        answer: The generated answer text
        source: Which baseline generated this ("training", "web_search", "knowledge_pack")
        latency_ms: Time taken to generate the answer in milliseconds
        cost_usd: Estimated cost of generating the answer in USD
    """

    question_id: str
    answer: str
    source: str  # "training", "web_search", "knowledge_pack"
    latency_ms: float
    cost_usd: float


@dataclass
class EvalMetrics:
    """Aggregated metrics for a single baseline evaluation.

    Attributes:
        accuracy: Accuracy score (0.0 to 1.0) based on ground truth comparison
        hallucination_rate: Rate of unsupported claims (0.0 to 1.0)
        citation_quality: Quality of citations provided (0.0 to 1.0)
        avg_latency_ms: Average response latency in milliseconds
        total_cost_usd: Total cost for all questions in USD
    """

    accuracy: float
    hallucination_rate: float
    citation_quality: float
    avg_latency_ms: float
    total_cost_usd: float


@dataclass
class EvalResult:
    """Complete evaluation result comparing all three baselines.

    Attributes:
        pack_name: Name of the knowledge pack being evaluated
        timestamp: ISO 8601 timestamp when evaluation was performed
        training_baseline: Metrics for training-only baseline
        web_search_baseline: Metrics for web search baseline
        knowledge_pack: Metrics for knowledge pack baseline
        surpasses_training: Whether pack beats training-only baseline
        surpasses_web: Whether pack beats web search baseline
        questions_tested: Number of questions used in evaluation
    """

    pack_name: str
    timestamp: str
    training_baseline: EvalMetrics
    web_search_baseline: EvalMetrics
    knowledge_pack: EvalMetrics
    surpasses_training: bool
    surpasses_web: bool
    questions_tested: int
