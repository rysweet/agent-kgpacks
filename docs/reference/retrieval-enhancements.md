# Retrieval Enhancements API Reference

Complete API reference for Issue 211 Improvements 4 (multi-query retrieval) and 5 (content quality scoring).

## KnowledgeGraphAgent — New Constructor Parameter

### `enable_multi_query`

```python
KnowledgeGraphAgent(
    db_path: str,
    anthropic_api_key: str | None = None,
    read_only: bool = True,
    use_enhancements: bool = True,
    few_shot_path: str | None = None,
    enable_reranker: bool = True,
    enable_multidoc: bool = True,
    enable_fewshot: bool = True,
    synthesis_model: str | None = None,
    cypher_pack_path: str | None = None,
    enable_multi_query: bool = False,          # NEW
)
```

**`enable_multi_query`** (`bool`, default `False`):
Generate 2 alternative phrasings of each question via Claude Haiku and fan out semantic search across all 3 queries for higher recall.

> **Data notice**: When `True`, the user's question (truncated to 500 characters) is sent to the Anthropic API for query expansion. Keep `False` for deployments with data-residency, PII, or offline constraints.

---

## New Class-Level Constants

### `CONTENT_QUALITY_THRESHOLD`

```python
KnowledgeGraphAgent.CONTENT_QUALITY_THRESHOLD: float = 0.3
```

Minimum quality score for a section to be included in synthesis context. Sections scoring below this value are filtered before Claude synthesis.

### `STOP_WORDS`

```python
KnowledgeGraphAgent.STOP_WORDS: frozenset[str]
```

Frozen set of ~80 common English function words excluded from keyword overlap scoring in `_score_section_quality`. Includes determiners (`a`, `an`, `the`), prepositions (`in`, `of`, `to`, `for`, `with`, `by`, `from`), pronouns, auxiliaries, and conjunctions.

**Example membership check**:

```python
assert "the" in KnowledgeGraphAgent.STOP_WORDS
assert "photosynthesis" not in KnowledgeGraphAgent.STOP_WORDS
```

---

## New Methods

### `_multi_query_retrieve`

```python
def _multi_query_retrieve(
    self,
    question: str,
    max_results: int = 5,
) -> list[dict]:
```

Retrieve results using the original question plus 2 alternative phrasings generated by Claude Haiku.

**Parameters**:

| Parameter | Type | Default | Description |
|---|---|---|---|
| `question` | `str` | — | Original natural language question. Truncated to 500 chars internally. |
| `max_results` | `int` | `5` | Maximum results per query (clamped to `[1, 20]`). After deduplication the final list may be smaller. |

**Returns**: `list[dict]` — Deduplicated results sorted descending by similarity. Each dict contains at minimum:
- `title` (`str`): article title (deduplication key)
- `similarity` (`float`): highest similarity score seen for this title across all queries
- any additional fields returned by `semantic_search` (e.g., `content`)

**Raises**: Does not raise. If the Haiku expansion call fails, falls back to searching only the original question and logs a warning.

**Model used for expansion**: `claude-haiku-4-5-20251001` (not the agent's `synthesis_model`).

**Example**:

```python
results = agent._multi_query_retrieve(
    "What experiments prove quantum entanglement?",
    max_results=5,
)
# returns e.g.:
# [
#   {"title": "Bell_test_experiments", "similarity": 0.92, "content": "..."},
#   {"title": "Aspect_experiment",     "similarity": 0.88, "content": "..."},
#   {"title": "EPR_paradox",           "similarity": 0.81, "content": "..."},
# ]
```

**Deduplication rule**: For any title that appears in multiple query result sets, the entry with the highest `similarity` is kept.

---

### `_score_section_quality`

```python
def _score_section_quality(
    self,
    content: str,
    question: str,
) -> float:
```

Score a section's quality for inclusion in synthesis context.

**Parameters**:

| Parameter | Type | Description |
|---|---|---|
| `content` | `str` | Section text content to evaluate. |
| `question` | `str` | User question; used to compute keyword overlap. Stop words are excluded. |

**Returns**: `float` in `[0.0, 1.0]`.

**Score formula**:

```
if word_count < 20:
    return 0.0                          # hard stub cutoff

length_score  = min(0.8, 0.2 + (word_count / 200) * 0.6)
keyword_score = min(0.2, overlap_ratio * 0.2)
                where overlap_ratio = |question_keywords ∩ content_words| / |question_keywords|
                and question_keywords excludes STOP_WORDS (case-insensitive)

return min(1.0, length_score + keyword_score)
```

**Score table**:

| `word_count` | Keywords matched | `length_score` | `keyword_score` | Total |
|---|---|---|---|---|
| < 20 | any | — | — | 0.0 |
| 20 | 0/0 or all stop words | 0.26 | 0.0 | 0.26 |
| 50 | 0 of N | 0.35 | 0.0 | 0.35 |
| 50 | all N | 0.35 | 0.2 | 0.55 |
| 100 | 0 of N | 0.50 | 0.0 | 0.50 |
| 200 | 0 of N | 0.80 | 0.0 | 0.80 |
| 200 | all N | 0.80 | 0.2 | 1.0 |
| 1000 | any | 0.80 | ≤ 0.2 | ≤ 1.0 |

**Example**:

```python
agent = KnowledgeGraphAgent(...)

# Stub — filtered
score = agent._score_section_quality("See also.", "quantum entanglement")
assert score == 0.0

# Short section with no keyword overlap
score = agent._score_section_quality(" ".join(["word"] * 50), "quantum entanglement")
# ≈ 0.35

# Long section with full keyword overlap
content = " ".join(["quantum", "entanglement"] * 100)
score = agent._score_section_quality(content, "quantum entanglement")
# ≈ 1.0
```

---

## Modified Methods

### `_fetch_source_text`

```python
def _fetch_source_text(
    self,
    source_titles: list[str],
    max_articles: int = 5,
    question: str | None = None,   # NEW optional parameter
) -> str:
```

Fetches section text for source articles. When `question` is provided, sections are scored via `_score_section_quality` and those below `CONTENT_QUALITY_THRESHOLD` are excluded before the result is assembled.

**New parameter**:

| Parameter | Type | Default | Description |
|---|---|---|---|
| `question` | `str \| None` | `None` | When provided, enables per-section quality filtering. When `None`, all sections are included (backwards-compatible). |

**Fallback**: If all sections across all articles are filtered below threshold (resulting in no assembled text), the agent runs a second query fetching `article.content` for all source titles. This is a **global** fallback — it activates only when the assembled `texts` list is empty. An individual article whose sections are all filtered will not receive a per-article fallback if at least one other article contributes passing sections.

---

### `_build_synthesis_context`

No signature change. Internally passes `question=question` to `_fetch_source_text` so that quality filtering activates automatically during synthesis.

---

### `_vector_primary_retrieve`

No signature change. Internally routes to `_multi_query_retrieve` when `self.enable_multi_query is True`, otherwise calls `semantic_search` directly as before.

```
enable_multi_query=False (default):
    semantic_search(question, top_k=max_results)

enable_multi_query=True:
    _multi_query_retrieve(question, max_results=max_results)
```

---

## Configuration Reference

| Parameter / Constant | Location | Default | Purpose |
|---|---|---|---|
| `enable_multi_query` | `__init__` | `False` | Opt-in multi-query retrieval via Haiku expansion |
| `CONTENT_QUALITY_THRESHOLD` | class attribute | `0.3` | Minimum quality score for section inclusion |
| `STOP_WORDS` | class attribute | frozenset of ~80 words | Excluded from keyword overlap in quality scoring |

---

## Integration with Phase 1 Enhancements

Both improvements are compatible with all Phase 1 flags:

```python
agent = KnowledgeGraphAgent(
    db_path="...",
    use_enhancements=True,        # Phase 1: enables reranker, multidoc, few-shot
    enable_reranker=True,         # Phase 1: graph PageRank reranking
    enable_multidoc=True,         # Phase 1: multi-document synthesis
    enable_fewshot=True,          # Phase 1: few-shot example injection
    enable_multi_query=True,      # Improvement 4: multi-query fan-out
    # Improvement 5: always active when question is available
)
```

---

## See Also

- [How-To: Retrieval Enhancements](../howto/retrieval-enhancements.md) — usage examples
- [Retrieval Enhancements Design](../concepts/retrieval-enhancements-design.md) — architecture and rationale
- [Phase 1 Enhancements API](./phase1-enhancements.md) — GraphReranker, MultiDocSynthesizer, FewShotManager
- [Test Suite](../../tests/agent/test_retrieval_enhancements.py) — 22 unit tests covering both improvements
